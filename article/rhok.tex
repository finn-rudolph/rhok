\documentclass[a4paper, 11pt, ngerman]{article}

\usepackage[utf8]{inputenc}
\usepackage[algoruled, nosemicolon]{algorithm2e}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[ngerman]{babel}
\usepackage[backend=biber, style=apa]{biblatex}
\usepackage{caption}
\usepackage{csquotes}
\usepackage[left=2.5cm, right=2.5cm, top=2.5cm, bottom=2cm]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{inconsolata}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{sectsty}
\usepackage[onehalfspacing]{setspace}
\usepackage{titlesec}

\title{Parametrisierung von Pollards Rho-Methode}
\author{Finn Rudolph}
\date{22.04.2024}

\addbibresource{rhok.bib}

\renewcommand{\thealgocf}{}

\newcommand{\C}{\mathbb{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\renewcommand{\P}{\mathbb{P}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\theoremstyle{plain}
\newtheorem{theorem}{Satz}
\newtheorem{lemma}{Lemma}
\newtheorem*{assumption*}{Annahme}

\theoremstyle{remark}
\newtheorem*{remark*}{Anmerkung}

\sectionfont{\large}
\subsectionfont{\normalsize}

\allowdisplaybreaks

\begin{document}

\titleformat{\subsection}[runin]{\bfseries}{\thesubsection}{0.5em}{}

\setcounter{tocdepth}{1}

\begin{titlepage}

    \noindent\rule{\textwidth}{0.4pt}

    \makeatletter
    \begin{flushleft}
        \textbf{\LARGE{\@title}} \\
        \vspace{1.5em}
        \@author \\
        \@date \\
        \vspace{1em}
        Erarbeitungsort: Hauptstraße 28, 96178 Pommersfelden \\
        Fachgebiet: Mathematik / Informatik \\
        Wettbewerbssparte: Jugend forscht \\
        Bundesland: Bayern \\
        Wettbewerbsjahr: 2024
    \end{flushleft}

    \vspace{0.2em}

    \section*{Projektüberblick}

    Pollards Rho-Methode ist einer der schnellsten Algorithmen zur Faktorisierung kleiner Zahlen. Bei der Implementierung des Algorithmus kann ein Parameter $k$ gewählt werden, der unter Umständen großen Einfluss auf die Laufzeit des Algorithmus hat, sowohl im positiven als auch im negativen Sinn. In dieser Arbeit soll untersucht werden, wie $k$ bestmöglich gewählt wird. Insbesondere ist der Fall interessant, wenn der Algorithmus auf mehreren Maschinen parallel ausgeführt wird, weil dann für jede Maschine $k$ separat gewählt werden kann. Für den Fall einer und zweier Maschinen konnten theoretische Ergebnisse erzielt werden, im Fall zweier Maschinen bleiben aber noch Fragen offen. Diese Ergebnisse decken sich mit durchgeführten Experimenten. Offen bleibt auch die Frage der optimalen Parametrisierung für drei oder mehr Maschinen.

    \vspace{0.5em}

    \tableofcontents

    \thispagestyle{empty}
\end{titlepage}

\newpage

\section{Zusammenfassung}

In dieser Arbeit wird die Frage behandelt, wie der Exponent der Iterationsfunktion $f : x \mapsto x^{2k} + 1$ in Pollards Rho-Methode optimal gewählt werden kann. Ein größerer Wert von $k$ erhöht grundsätzlich die Laufzeit, kann aber auch zu einer deutlichen Verringerung führen, wenn die Primfaktoren der zu faktorisierenden Zahl günstige Eigenschaften haben. Im Allgemeinen ist über die Primfaktoren allerdings nichts bekannt, denn sie sollen durch den Algorithmus bestimmt werden. Daher stellt sich die Frage, welcher Wert von $k$ im Mittel am besten ist. Es ergibt sich insbesondere dann ein interessantes Problem, wenn der Algorithmus auf mehreren Maschinen parallelisiert wird, weil $k$ dann für jede Maschine gewählt werden muss. Unter weithin anerkannten Annahmen über den Rho-Algorithmus konnten grundlegende Methoden zur Beantwortung dieser Frage entwickelt werden. Mit diesen war es möglich zu zeigen, dass $k = 1$ für eine Maschine optimal ist. Im Fall zweier Maschinen wird gezeigt, dass $k_1 = k_2 = 1$ besser ist als wenn $k_1$ und $k_2$ Primzahlen sind oder wenn $k_1 = k_2 > 1$ gilt. $k_i$ bezeichnet den Wert von $k$ für die $i$-te Maschine. Anschließend werden die theoretischen Ergebnisse mit Laufzeitmessungen verglichen.

\section{Motivation und Hintergrund}

Pollards Rho-Methode bleibt trotz der Existenz asymptotisch schnellerer Algorithmen einer der meist verwendeten Algorithmen zur Faktorisierung kleiner Zahlen. Gleichzeitig werden Leistungssteigerungen bei modernen Computern häufig durch größere Nebenläufigkeit (z. B. mehr Prozessorkerne) erzielt. Um die Rho-Methode schnellstmöglich zu implementieren, ist es also nötig zu untersuchen, wie sie am besten parallel ausgeführt werden kann. Die Wahl von $k$ geschieht für jede Maschine separat und hat unter Umständen großen Einfluss auf die Laufzeit, weshalb sie ein wichtiger Ansatzpunkt zur Weiterentwicklung der parallelen Rho-Methode ist.

Den Exponenten der Iterationsfunktion zu variieren, wurde bereits in der ersten Veröffentlichung der Rho-Methode (\cite{pol75}) in Betracht gezogen. In \cite{bp81} gelang durch eine Veränderung von $k$ (allerdings nur auf einer Maschine) die erstmalige Faktorisierung der achten Fermatzahl $F_8 = 2^{2^8} + 1$. Wenn Kongruenzen der Primfaktoren bekannt sind, wie im Fall von Fermatzahlen, kann $k$ gezielt gewählt werden, um die Laufzeit zu verringern. In dieser Arbeit wird allerdings der Fall allgemeiner Zahlen betrachtet, das heißt, keine Kongruenzen der Primfaktoren sind bekannt.

Bei einer direkten Parallelisierung der Rho-Methode auf $M$ Maschinen ergibt sich eine Verringerung der Laufzeit um einen Faktor $\sqrt M$. In \cite{cr99} wurde ein Verfahren vorgestellt, mit dem sich eine theoretische Verringerung um einen Faktor $(\log^2 M)/M$ erzielen lässt. Dafür muss der Wert von $k$ bei allen Maschinen gleich sein, weshalb das Verfahren nicht weiter in Betracht gezogen wird. Eine Methode, um bei $M$ Maschinen eine Laufzeitreduktion um einen Faktor $M$ zu erhalten, ist nicht bekannt (im Gegensatz zu dem verwandten Problem der Bestimmung diskreter Logarithmen, siehe \cite{vow99}).

In dieser Arbeit soll es also um folgende Frage gehen: \emph{Gegeben $M$ Maschinen und eine Zahl, über deren Primfaktoren nichts besonderes bekannt ist. Wie wählt man den Parameter k für jede Maschine optimal, um eine möglichst geringe Laufzeit zu erzielen?}

\section{Erläuterung der Rho-Methode}
\label{sec:pollards-rho-method}

Sei $n$ die zu faktorisierende Zahl. Es wird angenommen, dass $n$ ungerade und keine Potenz einer natürlichen Zahl ist, da sonst einfach ein Faktor gefunden werden kann.

\subsection{Die Iterationsfunktion und ihr funktionaler Graph.}

Sei $h : \Z/n\Z \to \Z/n\Z$ mit $h : x \mapsto x^{2k} + 1$ für einen Parameter $1 \le k \in \N$. Man wähle einen zufälligen Anfangswert $x_0 \in \Z/n\Z$ und betrachte die Folge $(x_i)_{i \in \N}$, definiert durch $x_i = h(x_{i - 1})$. Da $(x_i)_{i \in \N}$ über der endlichen Menge $\Z/n\Z$ definiert ist, ist die Folge ab einem bestimmten Punkt periodisch. Sei $p$ ein Primfaktor von $n$ und $\pi : \Z/n\Z \to \Z/p\Z$ die natürliche Projektion. Die Idee der Rho-Methode ist, zwei Folgenglieder $x_i, x_j \in \Z/n\Z$ zu finden, sodass $x_i \ne x_j$ aber $\pi(x_i) = \pi(x_j)$. Dann ist nämlich $\gcd(n, x_i - x_j)$ ein echter Faktor von $n$. Nimmt man an, dass die Periodenlänge von $(x_i)_{i \in \N}$ in $\Z/n\Z$ deutlich länger als die Periodenlänge in $\Z/p\Z$ ist, reicht es aus, $x_i, x_j$ mit $i \ne j$ zu finden, die kongruent modulo $p$ sind. Die Annahme ist plausibel, weil für den kleinsten Primfaktor $p \le \sqrt n$ gilt, es also deutlich weniger mögliche Werte für $\pi(x_i)$ als $x_i$ gibt. Im Folgenden ist $p$ immer der kleinste Primfaktor von $n$. Das Ereignis, dass eine Folge einen Wert zweimal annimmt, wird eine \emph{Kollision} in dieser Folge genannt. Es wird außerdem angenommen, dass die anderen Primfaktoren von $n$ so viel größer als $p$ sind, dass die Wahrscheinlichkeit einer Kollision modulo eines anderen Primfaktors vernachlässigbar gering ist. Zum Finden oben genannter $x_i, x_j$ ist es hilfreich, den funktionalen Graphen von $h$ zu betrachten.

\begin{definition}[Funktionaler Graph]
    Sei $X$ eine endliche Menge und $f: X \to X$ eine Abbildung. Der funktionale Graph von $f$, geschrieben $\gamma(f)$, ist der gerichtete Graph mit Knotenmenge $X$ und Kantenmenge $E$, wobei die Kante $(x, y) \in X \times X$ genau dann in $E$ liegt, wenn $f(x) = y$.
\end{definition}

Ein Beispiel eines funktionalen Graphen ist in Abbildung \ref{fig:fn-graph-17} zu sehen. Es ist leicht zu zeigen, dass jede Zusammenhangskomponente eines funktionalen Graphen aus einem Zyklus und an den Zyklusknoten gewurzelten Bäumen besteht. In $\gamma(h)$ ist $x_0$ also ein Knoten in einem der Bäume, der durch seinen Pfad zur Wurzel mit dem Zyklus seiner Zusammenhangskomponente verbunden ist. Die Folge $(x_i)_{i \in \N}$ startet bei $x_0$ und "`läuft"' durch den Graphen, wobei immer die eindeutige von einem Knoten ausgehende Kante entlanggegangen wird. An der Wurzel des Baums von $x_0$ wird der Zyklus in der Zusammenhangskomponente von $x_0$ betreten, und ab genau diesem Punkt ist $(x_i)_{i \in \N}$ periodisch. Bei Auftritt der ersten Kollision bildet der von $(x_i)_{i \in \N}$ abgelaufene Pfad die Form eines "`$\rho$"' in $\gamma(h)$.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \tikzset{every node/.style={
                    circle, draw=black, inner sep = 0pt, minimum size=19pt
                }}
        \small
        \node[circle, draw=black] (0) at (0, 0) {0};
        \node[circle, draw=black] (1) at (1.5, 0) {1};
        \node[circle, draw=black] (2) at (3, 0) {2};
        \node[circle, draw=black] (5) at (4, -1.3) {5};
        \node[circle, draw=black] (9) at (5.5, -1.3) {9};
        \node[circle, draw=black] (14) at (6.5, 0) {14};
        \node[circle, draw=black] (10) at (5.5, 1.3) {10};
        \node[circle, draw=black] (16) at (4, 1.3) {16};
        \node[circle, draw=black] (4) at (-1.1, -1.1) {4};
        \node[circle, draw=black] (13) at (-1.1, 1.1) {13};
        \node[circle, draw=black] (15) at (4, -2.7) {15};
        \node[circle, draw=black] (12) at (5.5, -2.7) {12};
        \node[circle, draw=black] (8) at (8, 0) {8};
        \node[circle, draw=black] (7) at (4, 2.7) {7};
        \node[circle, draw=black] (3) at (6.8, 2) {3};
        \node[circle, draw=black] (11) at (8.3, 1.3) {11};
        \node[circle, draw=black] (6) at (8.3, 2.7) {6};

        \draw[->] (0) -- (1);
        \draw[->] (1) -- (2);
        \draw[->] (2) -- (5);
        \draw[->] (5) -- (9);
        \draw[->] (9) -- (14);
        \draw[->] (14) -- (10);
        \draw[->] (10) -- (16);
        \draw[->] (16) -- (2);
        \draw[->] (13) -- (0);
        \draw[->] (4) -- (0);
        \draw[->] (7) -- (16);
        \draw[->] (3) -- (10);
        \draw[->] (15) -- (5);
        \draw[->] (12) -- (9);
        \draw[->] (6) -- (3);
        \draw[->] (11) -- (3);
        \draw[->] (8) -- (14);
        \normalsize
    \end{tikzpicture}

    \caption{Der funktionale Graph von $f : \Z/17\Z \to \Z/17\Z$ mit $f : x \mapsto x^2 + 1$.}
    \label{fig:fn-graph-17}
\end{figure}

\subsection{Kollisionserkennung im funktionalen Graphen modulo $\boldsymbol{p}$.}

Sei $f$ die Abbildung $h$, betrachtet in $\Z/p\Z$. Die Folge $(\pi(x_{i}))_{i \in \N}$ "`läuft"' analog durch $\gamma(f)$, beginnend von $\pi(x_0)$. Unser Ziel, das Finden einer Kollision von $(\pi(x_i))_{i \in \N}$, ist also äquivalent dazu, einen Knoten in $\gamma(f)$ zu finden, der zweimal in dem von $(\pi(x_i))_{i \in \N}$ abgelaufenen Pfad erscheint. Dafür kann Floyds Algorithmus zur Zykluserkennung in $\gamma(f)$ verwendet werden. Floyds Algorithmus macht sich zunutze, dass es ein $1 \le r \in \N$ mit $\pi(x_r) = \pi(x_{2r})$ geben muss (\cite{knu98}, S. 7). Sei $\mu(f, \pi(x_0))$ die Höhe von $\pi(x_0)$ in seinem Baum und $\lambda(f, \pi(x_0))$ die Länge des Zyklus von $\pi(x_0)$. Für das minimale solcher $r$ gilt $r \le \mu(f, \pi(x_0)) + \lambda(f, \pi(x_0))$ (\cite{knu98}, S. 7). Wir nennen $\nu(f, \pi(x_0)) = \mu(f, \pi(x_0)) + \lambda(f, \pi(x_0))$ die Rho-Länge von $\pi(x_0)$ in $f$. Es also genügt also, die Folgen $(\pi(x_i))_{i \in \N}$ und $(\pi(x_{2i}))_{n \in \N}$ gleichzeitig Glied für Glied zu berechnen und in jedem Schritt zu überprüfen, ob $\pi(x_i) = \pi(x_{2i})$. Das kann natürlich nicht explizit geschehen, da $p$ unbekannt ist. Stattdessen werden $(x_i)_{i \in \N}$ und $(x_{2i})_{i \in \N}$ Glied für Glied berechnet. Das Überprüfen, ob $\pi(x_i) = \pi(x_{2i})$ geschieht durch Berechnung von $\gcd(n, x_i - x_{2i})$. So erhält man nach maximal $\nu(f, \pi(x_0))$ Schritten die gewünschte Kollision. Die Methode kann wie folgt zusammengefasst werden. Dabei speichert $x$ nach der $i$-ten Iteration das $i$-te Glied der Folge $(x_i)_{i \in \N}$ und $y$ das $i$-te Glied von $(x_{2i})_{i \in \N}$.
\begin{algorithm}
    $x \gets $ zufällige natürliche Zahl zwischen $0$ und $n - 1$ \;
    $y \gets x$ \;
    \While{\emph{\textsc{true}}}
    {
        $x \gets x^{2k} + 1 \mod n$ \;
        $y \gets (y^{2k} + 1)^{2k} + 1 \mod n$ \;
        $g \gets \gcd(n, x - y)$ \;
        \If{$g \ne 1 \text{\emph{\textbf{ and }}} g \ne n$}
        {
            \Return{$g$} \;
        }
    }

    \caption{Pollards Rho-Methode}
\end{algorithm}

\subsection{Analyse der Rho-Methode.}

Die Analyse der Rho-Methode erweist sich als schwierig, es ist keine rigorose Laufzeitanalyse bekannt. Unter heuristischen Annahmen lässt sich die Laufzeit allerdings gut abschätzen. Als erste Vereinfachung wird statt der mittleren Anzahl an Iterationen von Floyds Algorithmus die mittlere Rho-Länge analysiert. Eine weitere Annahme dreht sich um die Verteilung der Rho-Längen in $\gamma(f)$, für deren Formulierung der Begriff einer asymptotischen Näherung benötigt wird.

\begin{definition}[Asymptotische Näherung]
    Eine Funktion $f : \R \to \R$ heißt genau dann asymptotische Näherung von einer Funktion $g : \R \to \R$, oder asymptotisch zu $g$, wenn
    \begin{align*}
        \lim_{x \to \infty} \frac {f(x)} {g(x)} = 1
    \end{align*}
    In diesem Fall schreiben wir $f \sim g$.
\end{definition}

\noindent Sei $A(n)$ die Menge der Abbildungen $\Z/n\Z \to \Z/n\Z$ für $n \in \N$. Über die Verteilung der Rho-Längen wird folgende Annahme getroffen, die auch \emph{Random Mapping Assumption} (RMA) genannt wird.

\begin{assumption*}[Random Mapping Assumption]
    Sei $f: \Z/p\Z \to \Z/p\Z$ mit $f : x \mapsto x^{2k} + 1$ und $d = \gcd(p - 1, 2k)$. Seien $x_0 \in \Z/p\Z$ und $y_0 \in \Z/((p - 1)/d)\Z$ zufällig und $g \in A((p - 1)/d)$ zufällig. Dann gilt $\P(\nu(f, x_0) = m) \sim \P(\nu(g, y_0) = m)$ für $p \to \infty$.
\end{assumption*}

\noindent In anderen Worten sagt die Random Mapping Assumption, dass sich die Verteilung der Rho-Längen von $f : x \mapsto x^{2k} + 1$ wie bei einer zufälligen Funktion aus $A((p - 1)/d)$ verhält. Insbesondere verhält sich $x \mapsto x^2 + 1$ bezüglich der Rho-Längen wie ein zufällige Funktion $\Z/(p - 1)\Z \to \Z/(p - 1)\Z$. \cite{bp81} geben eine Begründung für RMA. Im Folgenden wird statt $(p - 1)/d$ einfach $p/d$ verwendet, da $p \sim p - 1$ für $p \to \infty$.

Für $k = 1$ ist unter RMA die erwartete Anzahl an Iterationen der while-Schleife asymptotisch zu $\sqrt{\pi p / 2}$ (\cite{knu98}, S. 8). Da die Berechnung des größten gemeinsamen Teilers $O(\ln n)$ Schritte benötigt, ist die erwartete Laufzeit des Algorithmus $O(\sqrt p \ln n)$. Durch eine einfache Modifikation kann die Dauer des $\gcd$ amortisiert werden, sodass sich die Laufzeit auf $O(\sqrt p)$ verringert (\cite{bre80}). Damit ist pro Iteration also nur noch die Zeit zur Berechnung der $2k$-ten Potenzen von $x$ und $y$ relevant, was durchschnittlich in $c \lg 2k$ Schritten möglich ist, wobei $c$ eine hier unwichtige Konstante ist. Mit $\lg x$ wird der Logarithmus zur Basis 2 bezeichnet.

\section{Parallelisierung der Rho-Methode}

Sei $M$ die Anzahl verfügbarer Maschinen. Eine \emph{Maschine} meint hier nicht zwingend einen Computer, sondern eine Ressource, auf der ein sequentielles Programm ausgeführt werden kann, was beispielsweise auch ein Prozessorthread sein kann. Die Rho-Methode lässt sich parallelisieren, indem $M$ Anfangswerte ($x_0$ in Abschnitt \ref{sec:pollards-rho-method}) zufällig und unabhängig voneinander gewählt werden und der Algorithmus auf jeder der $M$ Maschinen ausgeführt wird, bis eine der Maschinen einen Faktor findet. Die Frage nach der optimalen Wahl von $k$ für diese $M$ Maschinen ist damit nicht klar: Durch ein größeres $k$ ist möglicherweise $\gcd(p - 1, 2k)$ groß, sodass die Zahl an Iterationen um einen Faktor $\sqrt{\gcd(p - 1, 2k) -1}$ sinkt. Allerdings steigt die Dauer einer Iteration um einen Faktor $\lg 2k$ wegen der Berechnung von $x^{2k}$. Da es sich bei den Veränderungen in der Laufzeit durch Veränderung von $k$ um konstante Faktoren handelt, wird für den Vergleich der Laufzeit nicht die $O$-Notation verwendet, sondern eine asymptotische Näherung für die erwartete Zahl an Zeiteinheiten bestimmt, wenn $p \to \infty$. Wir definieren eine \emph{Zeiteinheit} als die Dauer einer Iteration für $k = 1$, bei einer Maschine mit Parameter $k$ dauert eine Iteration also $\lg 2k$ Zeiteinheiten. Im Gegensatz zur $O$-Notation kann zwischen zwei Funktionen, die asymptotisch zueinander sind, für große $n$ kein konstanter Faktor liegen, sodass sich Veränderungen um konstante Faktoren sinnvoll vergleichen lassen.

Sei $k_1, \dots, k_M, 1 \le k_i \in \N$ eine Zuordnung von $k$-Werten für $M$ Maschinen. Mit $L_{k_1, \dots, k_M}(p)$ (oder kurz $L_{(k_i)}(p)$) wird die erwartete Laufzeit des parallelen Rho-Algorithmus mit entsprechenden $k$-Werten bezeichnet. Sei $h_i = p/(\gcd(p - 1, 2k_i) - 1)$. Unter RMA gilt
\begin{align}
    L_{(k_i)}(p) = \E \bigg ( \min_{i = 1}^M Z_i \lg 2k_i \bigg )
    \label{eq:lki-definition}
\end{align}
wobei $Z_i$ die gleichverteilte Zufallsvariable über $A(h_i) \times \Z/h_i\Z$ ist, mit $Z_i(f, x_0) = \nu(f, x_0)$ für $f \in A(h_i), x_0 \in \Z/h_i\Z$. In $L_{(k_i)}(p)$ ist $\gcd(p - 1, 2k_i)$ für alle $1 \le i \le M$ noch fixiert, der Erwartungswert über alle Möglichkeiten von $\gcd(p - 1, 2k_i)$ wird erst in Abschnitt \ref{sec:optimal-k} behandelt.

Wenn $k_i = k_j$, sind $Z_i$ und $Z_j$ nicht stochastisch unabhängig, weil sich die $i$-te und $j$-te Maschine dann im gleichen funktionalen Graphen bewegen. Es kann beispielsweise sein, dass die $i$-te Maschine der $j$-ten "hinterherläuft", wenn der Anfangswert der $i$-ten in einem Teilbaum des Anfangswerts der $j$-ten liegt. Diese Abhängigkeit sorgt für eine schlechtere Laufzeit und erschwert die Analyse des Algorithmus. Das Problem kann umgangen werden, indem die Funktion $f(x) = x^{2k_i} + c_i$ statt $f(x) = x^{2k_i} + 1$ für Maschine $i$ verwendet wird (\cite{cr99}, S. 6). Dabei wird $c_i \ne 0, -2$ für jede Maschine unabhängig gewählt, sodass $Z_i$ und $Z_j \ (i \ne j)$ immer stochastisch unabhängig sind, auch wenn $k_i = k_j$. Für folgende Berechnungen wird daher immer angenommen, dass $Z_i$ und $Z_j$ für $i \ne j$ unabhängig sind.

\begin{remark*}
    In der Version dieser Arbeit zum Regionalwettbewerb war mir das Paper von \cite{cr99} noch nicht bekannt. Daher war mir nicht klar, dass sich die Abhängigkeit von Maschinen mit gleichem $k$ durch unabhängige Wahl von $c_i$ umgehen lässt, sondern es wurde nur $c_i = 1$ für alle $i$ in Betracht gezogen. Folglich wurde der Fall unabhängiger Maschinen ($\Longleftrightarrow$ paarweise verschiedene $k_i$) vom Fall abhängiger Maschinen unterschieden. Für den Fall unabhängiger Maschinen wurde die Formel aus Abschnitt \ref{sec:formula-running-time} hergeleitet, die durch zufällige Wahl von $c_i$ nun allgemein gilt. Im Fall abhängiger Maschinen konnte eine Formel für $M = 2$ bestimmt werden. Sie ist hier für weitere Berechnungen nicht mehr relevant. Weil der zentrale Satz in der Herleitung aber auch unabhängig von der Anwendung auf die Rho-Methode interessant ist, soll dieser vorgestellt werden. Im Fall zweier abhängiger Maschinen bewegen sich beide Maschinen im gleichen funktionalen Graphen, beginnend von unabhängig gewählten Anfangsknoten. Die erwartete Anzahl an Iterationen ist also der Erwartungswert des Minimums der beiden Rho-Längen der Anfangsknoten. Diese Zahl wird unter RMA von folgendem Satz beschrieben.
\end{remark*}

\begin{theorem}
    \label{theorem:min-rho-len-m2}
    Sei $n \in \N$ und $A(n)$ die Menge der Abbildungen $\Z/n\Z \to \Z/n\Z$. Wir bezeichnen mit
    \begin{align*}
        \tau_n =  \frac 1 {n^{n + 2}}
        \sum_{g \in A(n)} \, \sum_{a \in \Z/n\Z} \, \sum_{b \in \Z/n\Z}
        \min\{\nu(g, a), \nu(g, b)\}
    \end{align*}
    die erwartete minimale Rho-Länge zweier zufälliger Knoten in einem zufälligen funktionalen Graphen von Größe $n$.  Es gilt
    \begin{align*}
        \tau_n \sim \frac {25} {32} \sqrt{\pi n / 2}
    \end{align*}
\end{theorem}

Der Vorfaktor in der Definition von $\tau_n$ ist $1/n^{n + 2}$, da es $n^n$ Abbildungen $\Z/n\Z \to \Z/n\Z$ gibt und für jede von diesen $n^2$ Paare an Anfangswerten. In dem Beweis wurde eine erzeugende Funktion für $\tau_n$ bestimmt, für deren Koeffizienten mithilfe analytischer Methoden aus \cite{fo90} eine asymptotische Näherung bestimmt werden konnte.

\section{Herleitung einer Formel für die erwartete Laufzeit}
\label{sec:formula-running-time}

In diesem Abschnitt wird eine Formel für $L_{(k_i)}(p)$ hergeleitet. Sei $h_i = p/(\gcd(p - 1, 2k_i) - 1)$. Mit (\ref{eq:lki-definition}) und der Definition des Erwartungswerts gilt
\begin{align}
    L_{(k_i)}(p) =
    \sum_{z_1 = 1}^{h_1} \P(Z_1 = z_1)
    \sum_{z_2 = 1}^{h_2} \P(Z_2 = z_2) \, \cdots
    \sum_{z_M = 1}^{h_M} \P(Z_M = z_M)
    \, \min_{i = 1}^M(z_i \lg 2k_i)
    \label{eq:lki-written-out}
\end{align}
wobei durch "`$\cdots$"' $M$ ineinander verschachtelte Summen über alle möglichen $z_i$ für jedes $1 \le i \le M$ angedeutet werden. Zunächst soll $\P(Z_i = z_i)$ bestimmt werden.

\begin{lemma}
    Man betrachte eine Maschine mit Parameter $k$ und $h = p/(\gcd(p - 1, 2k) - 1)$. Sei $Z$ die gleichverteilte Zufallsvariable über $A(h) \times \Z/h\Z$ mit $Z(f, x_0) = \nu(f, x_0)$. Es gilt
    \begin{align*}
        \P(Z = z) = \frac z h \prod_{j = 1}^{z - 1} \bigg (1 - \frac j h \bigg )
    \end{align*}

    \label{lemma:prob-s-z}
\end{lemma}

\begin{proof}
    Für eine zufällige Funktion $f \in A(h)$ ist die Wahrscheinlichkeit einer Kollision im $j$-ten Schritt $j/h$, wenn in den ersten $j - 1$ Schritten keine Kollision aufgetreten ist, da jeder der $h$ möglichen Werte gleich wahrscheinlich ist und $j$ von ihnen zu einer Kollision führen. Das Produkt ist also die Wahrscheinlichkeit, dass in den ersten $z - 1$ Schritten keine Kollision auftritt, und der Faktor $z/h$ ist die Wahrscheinlichkeit, dass im $z$-ten Schritt eine Kollision auftritt.
\end{proof}

Sei im Folgenden $Q(z, h) = (z/h) e^{-z^2/(2h)}$ und
\begin{align}
    F =
    \sum_{z_1 = 1}^{h_1} Q(z_1, h_1)
    \sum_{z_2 = 1}^{h_2} Q(z_2, h_2) \, \cdots
    \sum_{z_M = 1}^{h_M} Q(z_M, h_M)
    \, \min_{i = 1}^M(z_i \lg 2k_i)
    \label{eq:f-definition}
\end{align}
Das Ziel ist nun, eine einfache asymptotische Näherung für $F$ zu finden und zu zeigen, dass $L_{(k_i)}(p) \sim F$.


\begin{lemma}
    Sei $0 \le \delta < 1/6$. Mit der Notation von Lemma \ref{lemma:prob-s-z} gilt für $p \to \infty$ und $z \le h^{1/2 + \delta}$
    \begin{align*}
        |Q(z, h) - \P(Z = z)| = O \bigg ( \frac 1 {h^{1 - 4\delta}} \bigg )
    \end{align*}

    \label{lemma:prob-s-z-asmyp}
\end{lemma}

\begin{remark*}
    $z$ wird hier als Funktion von $h$ verstanden. Denn Lemma \ref{lemma:prob-s-z-asmyp} später auf (\ref{eq:lki-written-out}) für $p \to \infty$ anzuwenden, reicht eine Abschätzung für konstante $z_i$ nicht aus, da in (\ref{eq:lki-written-out}) über alle $1 \le z_i \le h_i$ summiert wird und $h_i = p/(\gcd(p - 1, 2k_i) - 1)$.

    Aus Lemma \ref{lemma:prob-s-z-asmyp} folgt $\lim_{p \to \infty} \P(Z = z) = Q(z, h)$ für $z \le h^{1/2 + \delta}$. Mit einer einfachen Rechnung lässt sich das auch für $z > h^{1/2 +\delta}$ zeigen. Daraus folgt aber noch nicht $L_{(k_i)}(p) \sim F$, da die Anzahl an Summanden in (\ref{eq:lki-written-out}) von $p$ abhängt. Das $\delta$ in Lemma \ref{lemma:prob-s-z-asmyp} wird später hilfreich sein, um zu zeigen, dass wirklich die gesamte Summe in (\ref{eq:lki-written-out}) asymptotisch zu $F$ ist.
\end{remark*}

\begin{proof}[Beweis von Lemma \ref{lemma:prob-s-z-asmyp}]
    Durch Anwenden der Restgliedabschätzung $e^x = 1 + x + O(x^2)$ für $|x| \le 1$ auf $\P(Z = z)$ erhalten wir
    \begin{align*}
        \P(Z = z) = \frac z h \prod_{j = 1}^{z - 1}
        \Bigg ( e^{-j/h} - O \bigg (\frac {j^2} {h^2} \bigg ) \Bigg )
    \end{align*}
    Daraus folgt
    \begin{align*}
        \vert Q(z, h) - \P(Z = z) \vert
         & = \frac z h \Bigg \vert
        e^{-z^2/(2h)} -
        \prod_{j = 1}^{z - 1}
        \Bigg ( e^{-j/h} - O \bigg (\frac {j^2} {h^2} \bigg ) \Bigg )
        \Bigg \vert                      \\
         & \le \frac z h \Bigg \vert
        e^{-z^2/(2h)} -
        \prod_{j = 1}^{z - 1} e^{-j/h}
        \Bigg \vert                      \\
         & \quad + \frac z h \Bigg \vert
        \sum_{k = 1}^{z - 1} O \bigg ( \frac {k^2} {h^2} \bigg )
        \prod_{j = 1, j \ne k}^{z - 1} e^{-j/h}
        - \sum_{k = 1}^{z - 1}\sum_{l = k+1}^{z - 1}
        O \bigg ( \frac {k^2l^2} {h^4} \bigg )
        \prod_{j = 1, j \ne k,l}^{z - 1} e^{-j/h}
        + \cdots
        \Bigg \vert
    \end{align*}
    Die Terme des ausmultiplizierten Produkts wurden nach der Zahl an $O(j^2/h^2)$-Faktoren gruppiert. Außerdem wurde die Dreiecksungleichung angewandt. Für den ersten Summanden gilt
    \begin{align*}
        \frac z h \Bigg \vert
        e^{-z^2/(2h)} -
        \prod_{j = 1}^{z - 1} e^{-j/h}
        \Bigg \vert
         & = \frac z h \Big \vert
        e^{-z^2/(2h)} -
        e^{-\sum_{j = 1}^{z - 1} j/h}
        \Big \vert                                       \\
         & = \frac z h \Big \vert
        e^{-z^2/(2h)} -  e^{-z(z - 1)/(2h)}
        \Big \vert                                       \\
         & = \frac z h e^{-z^2/(2h)} \Big \vert
        1 - e^{z/(2h)}
        \Big \vert                                       \\
         & \le \frac {z^2} {h^2}                         \\
         & = O \bigg ( \frac 1 {h^{1 - 2\delta}} \bigg )
    \end{align*}
    Von der dritten zur vierten Zeile wurde erneut die Restgliedabschätzung verwendet. Für den zweiten Summanden gilt
    \begin{align*}
               & \frac z h \Bigg \vert
        \sum_{k = 1}^{z - 1} O \bigg ( \frac {k^2} {h^2} \bigg )
        \prod_{j = 1, j \ne k}^{z - 1} e^{-j/h}
        - \sum_{k = 1}^{z - 1}\sum_{l = k+1}^{z - 1}
        O \bigg ( \frac {k^2l^2} {h^4} \bigg )
        \prod_{j = 1, j \ne k,l}^{z - 1} e^{-j/h}
        + \cdots
        \Bigg \vert                                           \\
        \le \, & \frac z h \Bigg (
        \sum_{k = 1}^{z - 1} O \bigg ( \frac {k^2} {h^2} \bigg )
        + \sum_{k = 1}^{z - 1}\sum_{l = k+1}^{z - 1}
        O \bigg ( \frac {k^2l^2} {h^4} \bigg )
        + \sum_{k = 1}^{z - 1}\sum_{l = k+1}^{z - 1}\sum_{m = l + 1}^{z - 1}
        O \bigg ( \frac {k^2l^2m^2} {h^6} \bigg )
        + \cdots \Bigg )                                      \\
        \le \, & \frac z h \Bigg (
        z \, O \bigg ( \frac {z^2} {h^2} \bigg )
        + z^2 \, O \bigg ( \frac {z^4} {h^4} \bigg )
        + z^3 \, O \bigg ( \frac {z^6} {h^6} \bigg )
        + \cdots \Bigg )                                      \\
        = \,   & O \Bigg ( \frac 1 {h^{1/2 - \delta}} \bigg (
        \frac 1 {h^{1/2 - 3 \delta}} + \frac 1 {h^{1 - 6\delta}}
        + \frac 1 {h^{3/2 - 9\delta}} + \cdots
        \bigg ) \Bigg )                                       \\
        = \,   & O \bigg ( \frac 1 {h^{1 - 4\delta}} \bigg )
    \end{align*}
    Von der ersten zur zweiten Zeile wurden mit der Dreiecksungleichung alle negativen Vorzeichen entfernt. Anschließend wurden die Produkte von $e^{-j/h}$ weggelassen, da sie $\le 1$ sind. In der letzten Zeile wurde die geometrische Summenformel verwendet.
\end{proof}

\begin{lemma}
    Sei $F$ wie in (\ref{eq:f-definition}) definiert. Es gilt
    \begin{align*}
        F \sim \sqrt{\pi p / 2} \Bigg ( \sum_{i = 1}^M \frac {\gcd(p - 1, 2k_i) - 1} {\lg^2 2k_i} \Bigg )^{-1/2}
    \end{align*}

    \label{lemma:f-asmyp}
\end{lemma}

\begin{proof}
    Die Summen in (\ref{eq:f-definition}) werden durch Integrale angenähert.
    \begin{align*}
        F \sim
        \int_0^{h_1} Q(z_1, h_1)
        \int_0^{h_2} Q(z_2, h_2) \cdots
        \int_0^{h_M} Q(z_M, h_M)
        \min_{i = 1}^M(z_i \lg 2k_i) \, dz_M \cdots dz_2 dz_1
    \end{align*}
    Für beliebiges $z_1 \in \R$ mit $z_1 \ge 0$ gilt
    \begin{align*}
        \int_0^{h_2} Q(z_2, h_2)
        \int_0^{h_3} Q(z_3, h_3) \cdots
        \int_0^{h_M} Q(z_M, h_M)
        \min_{i = 1}^M(z_i \lg 2k_i) \, dz_M \cdots dz_3 dz_2 \le p^M
    \end{align*}
    Folglich gilt
    \begin{align*}
            & \int_{h_1}^{\infty} Q(z_1, h_1)
        \int_0^{h_2} Q(z_2, h_2) \cdots
        \int_0^{h_M} Q(z_M, h_M)
        \min_{i = 1}^M(z_i \lg 2k_i) \, dz_M \cdots dz_2 dz_1 \\
        \le & \ p^M \int_{h_1}^{\infty}
        \frac {z_1} {h_1} e^{-z_1^2/(2h_1)} dz_1              \\
        =   & \; p^M e^{-h_1/2} \to 0 \quad (p \to \infty)
    \end{align*}
    Daraus folgt
    \begin{align*}
        F \sim
        \int_0^{\infty}
        \frac {z_1 e^{-z_1^2/(2h_1)}} {h_1}  \cdots
        \int_0^{\infty}
        \frac {z_M e^{-z_M^2/(2h_M)}} {h_M}
        \min_{i = 1}^M(z_i \lg 2k_i) \, dz_M \cdots dz_1
    \end{align*}
    Nun wird ein Variablenwechsel $y_i = z_i \lg 2k_i$ durchgeführt. Damit gilt
    \begin{align*}
        F \sim
        \Bigg (\prod_{i = 1}^M \frac 1 {\lg 2k_i} \Bigg )
        \int_0^{\infty}
        \frac {y_1 e^{-y_1^2 / (2h_1 \lg^2 2k_1)}} {h_1\lg 2k_1}  \cdots
        \int_0^{\infty}
        \frac {y_M e^{-y_M^2 / (2h_M \lg^2 2k_M)}} {h_M \lg 2k_M}
        \min_{i = 1}^M(y_i) \, dy_M \cdots dy_1
    \end{align*}
    Anstatt über alle $y_i$ von $0$ bis $\infty$ zu integrieren, wird nun unterschieden, welches der $y_i$ das Minimum ist. Wenn $y_j$ das Minimum ist, wird über $y_j$ von $0$ bis $\infty$ integriert und über $y_i \ (i \ne j)$ von $y_i$ bis $\infty$. Dadurch ist es möglich, $\min_{i = 1}^M (y_i)$ nach vorne zu ziehen, sodass die Integrale für $i \ne j$ unabhängig voneinander ausgewertet werden können. Schließlich wird über alle möglichen $j$ aufsummiert.
    \begin{align*}
        F & \sim
        \Bigg (\prod_{i = 1}^M \frac 1 {\lg 2k_i} \Bigg )
        \sum_{j = 1}^M \int_0^\infty
        \frac {y_j^2 e^{-y_j^2 / (2h_j \lg^2 2k_j)}} {h_j \lg 2k_j}
        \prod_{i = 1, i \ne j}^M \int_{y_j}^{\infty}
        \frac {y_i e^{-y_i^2 / (2h_i \lg^2 2k_i)}} {h_i \lg 2k_i} dy_i \; dy_j
    \end{align*}
    Für eine einfachere Notation werden die Integrationsvariablen von $y_j$ zu $y$ und von $y_i$ zu $x$ umbenannt. Zunächst werden die Integrale im Produkt rechts ausgewertet. Es gilt
    \begin{align*}
        \int_{y}^{\infty}
        \frac {x e^{-x^2 / (2h_i \lg^2 2k_i)}} {h_i \lg 2k_i} dx
         & = e^{-x^2/(2h_i \lg^2 2k_i)} (- \lg 2k_i) \Big \vert_{y}^{\infty} \\
         & = e^{-y^2/(2h_i \lg^2 2k_i)} \lg 2k_i
    \end{align*}
    Also gilt
    \begin{align*}
        F & \sim
        \Bigg (\prod_{i = 1}^M \frac 1 {\lg 2k_i} \Bigg )
        \sum_{j = 1}^M \int_0^\infty
        \frac {y^2 e^{-y^2 / (2h_j \lg^2 2k_j)}} {h_j \lg 2k_j}
        \prod_{i = 1, i \ne j}^M e^{-y^2/(2h_i \lg^2 2k_i)} \lg 2k_i \; dy \\
          & = \Bigg ( \prod_{i = 1}^M \frac 1 {\lg 2k_i} \Bigg )
        \sum_{j = 1}^M \int_0^\infty
        \frac {y^2} {h_j \lg^2 2k_j} \,
        \prod_{i = 1}^M e^{-y^2/(2h_i \lg^2 2k_i)} \lg 2k_i \; dy          \\
          & = \sum_{j = 1}^M \int_0^\infty
        \frac {y^2} {h_j \lg^2 2k_j} \,
        \prod_{i = 1}^M e^{-y^2/(2h_i \lg^2 2k_i)} \; dy                   \\
          & = \Bigg ( \sum_{i = 1}^M \frac 1 {h_i \lg^2 2k_i} \Bigg )
        \int_0^\infty
        y^2 \,e^{- \sum_{i = 1}^M y^2/(2h_i \lg^2 2k_i)} \; dy
    \end{align*}
    Um das Integral auszuwerten, wurde die Tabelle in Wikipedia: \cite{gint} verwendet. Damit erhält man schließlich
    \begin{align*}
        F & \sim \Bigg (\sum_{i = 1}^M \frac 1 {h_i \lg^2 2k_i} \Bigg ) \,
        \sqrt {\pi / 2} \
        \Bigg ( \sum_{i = 1}^M \frac 1 {h_i \lg^2 2k_i} \Bigg )^{-3/2}     \\
          & = \sqrt{\pi p / 2} \; \Bigg (
        \sum_{i = 1}^M \frac {\gcd(p - 1, 2k_i) - 1} {\lg^2 2k_i} \Bigg )^{-1/2} \qedhere
    \end{align*}
\end{proof}

\begin{lemma}
    Sei $Q(z, h) = (z/h)e^{-z^2/(2h)}$ und $\delta > 0$. Dann gilt für $h \to \infty$
    \begin{align*}
        \sum_{z = h^{1/2 + \delta}}^h Q(z, h) \le he^{-h^{2\delta}/2}
    \end{align*}

    \label{lemma:q-large-z-asymp}
\end{lemma}

\begin{proof}
    Da $e^{-z^2/(2h)}$ für $z \ge 0$ monoton fällt, gilt
    \begin{align*}
         & \sum_{z = h^{1/2 + \delta}}^h \frac z h e^{-z^2/(2h)}
        \le \sum_{z = h^{1/2 + \delta}}^h e^{-h^{2\delta}/2}
        \le he^{-h^{2\delta}/2} \qedhere
    \end{align*}
\end{proof}

Um $L_{(k_i)}(p) \sim F$ zu zeigen, schreibe man
\begin{align*}
    F = & \sum_{z_1 = 1}^{h_1^{9/16}} Q(z_1, h_1)
    \sum_{z_2 = 1}^{h_2} Q(z_2, h_2)    \cdots
    \sum_{z_M = 1}^{h_M} Q(z_M, h_M)
    \min_{i = 1}^M (z_i \lg 2k_i)                 \\
        & \quad +
    \sum_{z_1 = h_1^{9/16}}^{h_1} Q(z_1, h_1)
    \sum_{z_2 = 1}^{h_2} Q(z_2, h_2)    \cdots
    \sum_{z_M = 1}^{h_M} Q(z_M, h_M)
    \min_{i = 1}^M (z_i \lg 2k_i)
\end{align*}
Da die Summen über $z_2$ bis $z_M$ durch ein Polynom in $p$ beschränkt sind, geht die zweite Zeile nach Lemma \ref{lemma:q-large-z-asymp} gegen 0. Indem auf die erste Summe Lemma \ref{lemma:prob-s-z-asmyp} mit $\delta = 1/16$ angewandt wird, folgt
\begin{align*}
    F \sim \sum_{z_1 = 1}^{h_1^{9/16}}
    \Big ( \P(Z_1 = z_1) + O \Big ( h_1^{-3/4} \Big ) \Big )
    \sum_{z_2 = 1}^{h_2} Q(z_2, h_2)    \cdots
    \sum_{z_M = 1}^{h_M} Q(z_M, h_M)
    \min_{i = 1}^M (z_i \lg 2k_i)
\end{align*}
Nach Lemma \ref{lemma:f-asmyp} gilt $\sum_{z_2 = 1}^{h_2} Q(z_2, h_2) \cdots \sum_{z_M = 1}^{h_M} Q(z_M, h_M) \min_{i = 1}^M (z_i \lg 2k_i) = O(\sqrt p)$. Folglich ist die Summe aller Terme mit einem $O \big (h_1^{-3/4} \big )$-Faktor durch $O(p^{5/16})$ beschränkt. Für eine asymptotische Näherung von $F$ können sie also weggelassen werden. Indem dieses Argument für $Q(z_2, h_2) \dots, Q(z_M, h_M)$ wiederholt wird, können alle $Q(z_i, h_i)$ durch $\P(Z_i = z_i)$ ersetzt werden. Da $\P(z_i, h_i) = O(Q(z_i, h_i))$, können die oberen Grenzen der Summen von $h_i^{9/16}$ durch eine erneute Anwendung von Lemma \ref{lemma:q-large-z-asymp} zurück zu $h_i$ geändert werden. Daraus folgt $L_{(k_i)}(p) \sim F$.

Aus Lemma \ref{lemma:f-asmyp} und $L_{(k_i)}(p) \sim F$ folgt nun eine asymptotische Näherung für die Laufzeit der Rho-Methode.
\begin{theorem}
    Unter der Random Mapping Assumption gilt für die erwartete Laufzeit der Rho-Methode auf $M$ Maschinen mit $k$-Werten $k_1, \dots, k_M$
    \begin{align}
        L_{k_1, \dots, k_M}(p) \sim
        \sqrt{\pi p / 2} \Bigg ( \sum_{i = 1}^M
        \frac {\gcd(p - 1, 2k_i) - 1} {\lg^2 2k_i} \Bigg )^{-1/2}
        \label{eq:lki-asymp}
    \end{align}

    \label{theorem:lki-asymp}
\end{theorem}

\section{Bestimmung optimaler Exponenten für die Rho-Methode}
\label{sec:optimal-k}

In diesem Abschnitt wird die Frage behandelt, wie der Parameter $k$ bei $M$ Maschinen bestmöglich gewählt werden kann. Mit Satz \ref{theorem:lki-asymp} konnten Ergebnisse in den Fällen $M = 1$ und $M = 2$ erzielt werden. Die grundlegende Strategie ist, den Erwartungswert von $L_{k_1, \dots, k_M}(p)$ über alle Möglichkeiten von $\gcd(p - 1, 2k_i)$ für alle $1 \le i \le M$ zu bilden und so einen Wert für die erwartete Laufzeit in Abhängigkeit der $k_i$ zu erhalten. Da $p - 1$ gerade ist, gilt $\gcd(p-1, 2k_i) = 2\gcd((p - 1)/2, k_i)$. Weitere Kongruenzen von $p - 1$ sind im Allgemeinen nicht bekannt, weshalb angenommen wird, dass jeder Rest von $(p- 1)/2$ modulo $k_i$ gleich wahrscheinlich ist.

\begin{theorem}
    \label{theorem:optimal-k-m1}
    Sei $L_k(p)$ wie in (\ref{eq:lki-definition}) definiert. Der Erwartungswert $\E(L_k(p))$ über alle möglichen $\gcd((p - 1)/2, k)$ nimmt ein globales Minimum für $k = 1$ an.
\end{theorem}

\begin{proof}
    Durch Einsetzen von $M = 1$ in (\ref{eq:lki-asymp}) erhalten wir
    \begin{align*}
        L_k(p) \sim \sqrt {\pi p / 2} \;
        \frac {\lg 2k} {\sqrt{\gcd(p - 1, 2k) - 1}}
    \end{align*}
    Die erwartete Laufzeit im Fall $k = 1$ ist folglich $\sqrt{\pi p/2}$. Es wird also gezeigt, dass $\E(L_k(p)) > \sqrt{\pi p / 2}$ für $k > 1$. Mit $\varphi$ wird die eulersche Phifunktion bezeichnet. Dann gilt
    \begin{align*}
        \E(L_k(p))
        \sim \sqrt{\pi p / 2} \, \lg (2k) \,
        \sum_{d | k} \frac {\P(\gcd((p - 1)/2, k) = d)}
        { \sqrt {2d - 1}} \nonumber
        \ge \sqrt{\pi p / 2} \, \lg (2k) \, \frac {\varphi(k)} k
    \end{align*}
    Für die Ungleichung wurde statt der Summe über alle Teiler nur $d = 1$ betrachtet. Da es $\varphi(k)$ teilerfremde Zahlen kleiner $k$ gibt, ist $\P(\gcd((p - 1)/2, k) = 1) = \varphi(k)/k$. Nach \cite{rs62}, Theorem 15 gilt $ \varphi(k) / k > 1 / (e^\gamma \ln (\ln (k)) + 2.51 / \ln (\ln (k)))$ für $k \ge 3$, wobei $\gamma \approx 0.5772$ die Euler-Mascheroni-Konstante ist. Für $k \ge e^e$ folgt daraus $\varphi(k) / k > 1/(e^\gamma \ln(\ln(k)) + 2.51)$. Indem nun gezeigt wird, dass $\lg (2k) / (e^\gamma \ln (\ln (k)) + 2.51) > 1$ für $k \ge 16$ wird der Satz im Fall $k \ge 16$ bewiesen. Sei $f(x) = \lg (2x) / (e^\gamma \ln (\ln (x)) + 2.51)$. Es gilt $f(16) \approx 1.1557$ und
    \begin{align*}
        f'(x)
        = \frac {\ln (x)(\ln (\ln (x)) + 1.51) - \ln 2}
        {x \ln (2) \ln (x)(\ln(\ln(x)) + 2.51)^2}
    \end{align*}
    Für $x \ge 16$ ist der Nenner von $f'$ positiv, denn $x > 0$ und $\ln x > 0$, und weil $\ln \ln x > 1$ für $x \ge 16$ ist der Term unter dem Quadrat positiv. Der Zähler ist ebenfalls positiv, da $\ln x \ge 1$ und $\ln \ln x \ge 1$, woraus $\ln(x)(\ln(\ln(x)) + 1.51) \ge 1 \cdot (1 + 1.51) = 2.51 > \ln 2$ folgt. Also ist $f$ streng monoton steigend für $x \ge 16$, und da bereits $f(16) > 1$ gezeigt wurde, folgt $f(x) > 1$ für $x \ge 16$. Der Fall $k < 16$ wurde durch Ausrechnen von (\ref{eq:lki-asymp}) für $2 \le k \le 15$ überprüft.
\end{proof}

\begin{theorem}
    \label{theorem:optimal-k-m2}
    Sei $L_{k_1, k_2}(p)$ wie in (\ref{eq:lki-definition}) definiert. Man nehme RMA an und bilde den Erwartungswert $\E(L_{k_1, k_2})$ über alle möglichen $\gcd((p - 1)/2, k_i)$ für $i = 1, 2$.
    \begin{enumerate}
        \item Wenn $k_1, k_2$ Primzahlen sind, gilt $\E(L_{1, 1}(p)) < \E(L_{k_1, k_2}(p))$.
        \item Wenn $1 < k \in \N$, gilt $\E(L_{1, 1}(p)) < \E(L_{k, k}(p))$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Nach Satz \ref{theorem:lki-asymp} gilt
    \begin{align*}
        L_{k_1, k_2}(p)
         & \sim \sqrt{\pi p / 2} \
        \Bigg ( \frac {\gcd(p - 1, 2k_1) - 1} {\lg^2 2k_1} +
        \frac {\gcd(p -1, 2k_2) - 1} {\lg^2 2k_2} \Bigg )^{-1/2}
    \end{align*}
    Durch Einsetzen von $k_1 = k_2 = 1$ erhalten wir $L_{1, 1}(p) \sim \sqrt{\pi p / 4}$. Es gilt also in beiden Teilen zu zeigen, dass der Erwartungswert größer ist. Zunächst wird Teil 1 bewiesen.

    Durch Bilden des Erwartungswerts über alle möglichen $\gcd((p - 1)/2, k_i)$ für $i = 1, 2$ erhält man
    \begin{align}
        \E(L_{k_1, k_2})
         & \sim \sqrt{\pi p / 2}
        \sum_{d_1 | k_1} \P(\gcd((p - 1)/2, k_1) = d_1)
        \nonumber                                                 \\
         & \qquad \sum_{d_2 | k_2} \P(\gcd((p - 1)/2, k_2) = d_2)
        \Bigg ( \frac {2d_1 - 1} {\lg^2 2k_1}
        + \frac {2d_2 - 1} {\lg^2 2k_2} \Bigg )^{-1/2}
        \nonumber                                                 \\
         & \ge \sqrt{\pi p / 2} \
        \frac {\varphi(k_1) \varphi(k_2)} {k_1k_2}
        \Bigg (\frac 1 {\lg^2 2k_1} + \frac 1 {\lg^2 2k_2} \Bigg )^{-1/2}
        \nonumber                                                 \\
         & = \sqrt{\pi p / 2} \
        \frac {(k_1 - 1) (k_2- 1)} {k_1k_2}
        \sqrt{\frac{\lg^2(2k_1) \lg^2(2k_2)}{\lg^2(2k_1) + \lg^2(2k_2)}}
        \label{eq:two-mach-lowerb}
    \end{align}
    Wie bei $M = 1$ wurden die Summen über alle Teiler von $k_1, k_2$ durch den Wert bei $d_1 = d_2 = 1$ nach unten begrenzt. Die Terme $(k_i - 1)/k_i$ sind streng monoton steigend in $k_i$. Ebenso ist das Argument der nachfolgenden Wurzel in (\ref{eq:two-mach-lowerb}) streng monoton steigend in jedem der $k_i$. Um das zu zeigen, sei $x = \lg^2 2k_1, y = \lg^2 2k_2$ und $x' > x$. Dann gilt
    \begin{align*}
        \frac {x'y} {x' + y}
        = \frac {x'y} {x' + y} \, \frac {x + y} {xy} \, \frac {xy} {x + y}
        = \frac {xx'y + x'y^2} {xx'y + xy^2} \, \frac {xy} {x + y}
        > \frac {xy} {x + y}
    \end{align*}
    da $x, x', y > 0$ und $x < x'$. Der Term ist symmetrisch in $x$ und $y$, womit er auch streng monoton steigend in $y$ ist. Da die Wurzelfunktion streng monoton steigt und die Verkettung streng monoton steigender Funktionen streng monoton steigt, folgt, dass die gesamte Wurzel auf der rechten Seite von (\ref{eq:two-mach-lowerb}) streng monoton steigt. Weil nun jeder einzelne Faktor in (\ref{eq:two-mach-lowerb}) streng monoton steigt und positiv ist, ist ganz (\ref{eq:two-mach-lowerb}) streng monoton steigend in den $k_i$. Indem man $k_1 = k_2 = 3$ in (\ref{eq:two-mach-lowerb}) einsetzt, sieht man, dass $E(L_{3, 3}(p)) \ge 0.8123 \sqrt{\pi p /2}  > \sqrt{\pi p / 4}$. Weil (\ref{eq:two-mach-lowerb}) symmetrisch in $k_1, k_2$ ist, kann $k_1 < k_2$ angenommen werden. Dann folgt aus der Monotonie von (\ref{eq:two-mach-lowerb}), dass $E(L_{k_1, k_2}(p)) > \E(L_{1, 1}(p))$, wenn $k_1 \ge 3$. Es bleibt also lediglich der Fall $k_1 = 2$. Durch Einsetzen von $k_1 = 2, \; k_2 = 7$ in (\ref{eq:two-mach-lowerb}) gilt $\E(L_{2, 7}(p)) \ge 0.7588 \sqrt{\pi p / 2} > \sqrt{\pi p / 4}$. Aus der Monotonie von (\ref{eq:two-mach-lowerb}) folgt $\E(L_{k_1, k_2}(p)) > \E(L_{1, 1}(p))$ für $k_1 = 2$ und $k_2 \ge 7$. Die übrigen Fälle $k_1 = 2$ und $k_2 = 2, 3, 5$ wurden nachgerechnet.

    Nun zum Beweis von Teil 2. Aus (\ref{eq:lki-asymp}) folgt $L_{k, k}(p) = L_{k}(p) / \sqrt 2$ für $1 \le k \in \N$. Damit folgt Teil 2 des Satzes aus Satz \ref{theorem:optimal-k-m1}.
\end{proof}

\section{Experimentelle Ergebnisse}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                xlabel = {$k$},
                xmin = 1,
                xmax = 48,
                xtick = {1, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48},
                width = \textwidth,
                height = 260pt,
                legend pos = north west,
                legend style = {draw = none},
                legend cell align = left,
            ]

            \addplot[color=magenta,mark=square]
            coordinates{
                    (1, 1.0)
                    (2, 1.5773502691896257)
                    (3, 2.1086517918741277)
                    (4, 2.21648605664914)
                    (5, 2.8790043489023804)
                    (6, 2.332272327437964)
                    (7, 3.414299970503978)
                    (8, 2.89543195056782)
                    (9, 3.3067332978837425)
                    (10, 2.970093877947532)
                    (11, 4.142494904167608)
                    (12, 2.7949482208102387)
                    (13, 4.411181889332409)
                    (14, 3.4111279805567123)
                    (15, 3.481018974295858)
                    (16, 3.594729442047154)
                    (17, 4.840295239186588)
                    (18, 3.2665648302249286)
                    (19, 5.017128905823505)
                    (20, 3.426648342312123)
                    (21, 3.952865384732847)
                    (22, 4.006284568144385)
                    (23, 5.319207262349245)
                    (24, 3.3342189545431045)
                    (25, 4.848341222073144)
                    (26, 4.224515025049569)
                    (27, 4.541184581320172)
                    (28, 3.8606214340939586)
                    (29, 5.682737117278753)
                    (30, 3.3580839014528188)
                    (31, 5.786717613861166)
                    (32, 4.303622115889641)
                    (33, 4.585058767874234)
                    (34, 4.57165798930078)
                    (35, 4.768544753994481)
                    (36, 3.65286546982577)
                    (37, 6.061272505622063)
                    (38, 4.714254318317245)
                    (39, 4.815669489895146)
                    (40, 3.9872807230736402)
                    (41, 6.219718898826906)
                    (42, 3.7480426730792065)
                    (43, 6.293026650584624)
                    (44, 4.440755450349039)
                    (45, 4.475806923989725)
                    (46, 4.957283888509379)
                    (47, 6.429590774020685)
                    (48, 3.903718627468377)
                };

            \addplot[color=blue,mark=square]
            coordinates {
                    (1 ,   1)
                    (2 ,   1.2688871624076672)
                    (3 ,   1.5448360772795062)
                    (4 ,   1.6215294878078745)
                    (5 ,   2.1260552548319587)
                    (6 ,   1.7210271616473245)
                    (7 ,   2.5083228373472504)
                    (8 ,   2.006075780278468)
                    (9 ,   2.2840987997737323)
                    (10,   2.227057271909877)
                    (11,   3.0667905710118877)
                    (12,   2.02973927462346)
                    (13,   3.1096795366509973)
                    (14,   2.554240766520122)
                    (15,   2.605128864950923)
                    (16,   2.4065268921363367)
                    (17,   3.3463078632578274)
                    (18,   2.3995424079135566)
                    (19,   3.636437145493917)
                    (20,   2.540642287388499)
                    (21,   2.798891347254288)
                    (22,   3.0196492908359134)
                    (23,   3.962603150398965)
                    (24,   2.3707754814488204)
                    (25,   3.263084687726768)
                    (26,   3.055858996661355)
                    (27,   3.1536357812541125)
                    (28,   2.8452919940049712)
                    (29,   4.002758086162577)
                    (30,   2.7051029645392757)
                    (31,   4.281180949475698)
                    (32,   2.798678843877791)
                    (33,   3.0338163972786867)
                    (34,   3.236647402168213)
                    (35,   3.456162662926002)
                    (36,   2.6958680662121215)
                    (37,   4.206046640838136)
                    (38,   3.480612316774627)
                    (39,   3.530674663584416)
                    (40,   2.894119424906177)
                    (41,   4.195187693016042)
                    (42,   2.8835503555481226)
                    (43,   4.500107134645032)
                    (44,   3.324245578471752)
                    (45,   3.2505677313318966)
                    (46,   3.7547741175937004)
                    (47,   4.7967391294287784)
                    (48,   2.7134203084992854)};

            \legend{Formel (\ref{eq:lki-asymp}), Gemessene Laufzeit}
        \end{axis}
    \end{tikzpicture}
    \caption{Die durchschnittliche gemessene Laufzeit des Rho-Algorithmus für $M = 1$ und Werte von Formel (\ref{eq:lki-asymp}) für $1 \le k \le 48$.}
    \label{fig:measurements-m1}

    \vspace{2em}

    \small

    \begin{tabular}{c|cccccccccccccc}
        $k_1 \backslash k_2$ & 1                                & 2                                & 3                                & 4                                & 5                                & 6                                & 7                                & 8                                & 9                                & 10                               & 11                               & 12                               & 13                               & 14                               \\
        \hline
        1                    & \textcolor[HTML]{ 0020ff }{1.00} & \textcolor[HTML]{ 0b20f3 }{1.10} & \textcolor[HTML]{ 1520e9 }{1.18} & \textcolor[HTML]{ 1720e7 }{1.20} & \textcolor[HTML]{ 1d20e1 }{1.25} & \textcolor[HTML]{ 1b20e3 }{1.23} & \textcolor[HTML]{ 1f20df }{1.27} & \textcolor[HTML]{ 1d20e1 }{1.25} & \textcolor[HTML]{ 2020de }{1.27} & \textcolor[HTML]{ 2020de }{1.27} & \textcolor[HTML]{ 2220dc }{1.29} & \textcolor[HTML]{ 2020de }{1.27} & \textcolor[HTML]{ 2220dc }{1.29} & \textcolor[HTML]{ 2120dd }{1.28} \\
        2                    &                                  & \textcolor[HTML]{ 2520d9 }{1.32} & \textcolor[HTML]{ 2c20d2 }{1.38} & \textcolor[HTML]{ 3320cb }{1.44} & \textcolor[HTML]{ 3c20c2 }{1.51} & \textcolor[HTML]{ 3820c6 }{1.48} & \textcolor[HTML]{ 4120bd }{1.56} & \textcolor[HTML]{ 3f20bf }{1.53} & \textcolor[HTML]{ 4120bd }{1.56} & \textcolor[HTML]{ 4320bb }{1.57} & \textcolor[HTML]{ 4720b7 }{1.61} & \textcolor[HTML]{ 4120bd }{1.56} & \textcolor[HTML]{ 4720b7 }{1.61} & \textcolor[HTML]{ 4620b8 }{1.60} \\
        3                    &                                  &                                  & \textcolor[HTML]{ 4d20b1 }{1.66} & \textcolor[HTML]{ 4720b7 }{1.60} & \textcolor[HTML]{ 5820a6 }{1.75} & \textcolor[HTML]{ 5220ac }{1.70} & \textcolor[HTML]{ 5f209f }{1.81} & \textcolor[HTML]{ 5520a9 }{1.72} & \textcolor[HTML]{ 652099 }{1.86} & \textcolor[HTML]{ 5d20a1 }{1.79} & \textcolor[HTML]{ 692095 }{1.89} & \textcolor[HTML]{ 5e20a0 }{1.80} & \textcolor[HTML]{ 6a2094 }{1.90} & \textcolor[HTML]{ 63209b }{1.84} \\
        4                    &                                  &                                  &                                  & \textcolor[HTML]{ 5520a9 }{1.72} & \textcolor[HTML]{ 5f209f }{1.81} & \textcolor[HTML]{ 5620a8 }{1.74} & \textcolor[HTML]{ 692095 }{1.89} & \textcolor[HTML]{ 652099 }{1.86} & \textcolor[HTML]{ 652099 }{1.86} & \textcolor[HTML]{ 692095 }{1.89} & \textcolor[HTML]{ 73208b }{1.98} & \textcolor[HTML]{ 652099 }{1.86} & \textcolor[HTML]{ 74208a }{1.98} & \textcolor[HTML]{ 6f208f }{1.94} \\
        5                    &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 91206d }{2.23} & \textcolor[HTML]{ 70208e }{1.95} & \textcolor[HTML]{ 93206b }{2.25} & \textcolor[HTML]{ 7e2080 }{2.07} & \textcolor[HTML]{ 8d2071 }{2.20} & \textcolor[HTML]{ 93206b }{2.25} & \textcolor[HTML]{ a72057 }{2.42} & \textcolor[HTML]{ 82207c }{2.10} & \textcolor[HTML]{ a92055 }{2.44} & \textcolor[HTML]{ 982066 }{2.29} \\
        6                    &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 6f208f }{1.94} & \textcolor[HTML]{ 782086 }{2.02} & \textcolor[HTML]{ 73208b }{1.97} & \textcolor[HTML]{ 7d2081 }{2.06} & \textcolor[HTML]{ 772087 }{2.01} & \textcolor[HTML]{ 82207c }{2.11} & \textcolor[HTML]{ 782086 }{2.02} & \textcolor[HTML]{ 83207b }{2.11} & \textcolor[HTML]{ 7d2081 }{2.06} \\
        7                    &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ ba2044 }{2.58} & \textcolor[HTML]{ 8d2071 }{2.20} & \textcolor[HTML]{ a3205b }{2.38} & \textcolor[HTML]{ a2205c }{2.38} & \textcolor[HTML]{ c72037 }{2.69} & \textcolor[HTML]{ 962068 }{2.27} & \textcolor[HTML]{ c92035 }{2.71} & \textcolor[HTML]{ ba2044 }{2.58} \\
        8                    &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 872077 }{2.15} & \textcolor[HTML]{ 862078 }{2.14} & \textcolor[HTML]{ 8b2073 }{2.18} & \textcolor[HTML]{ 9b2063 }{2.32} & \textcolor[HTML]{ 852079 }{2.13} & \textcolor[HTML]{ 9c2062 }{2.33} & \textcolor[HTML]{ 952069 }{2.27} \\
        9                    &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ b0204e }{2.50} & \textcolor[HTML]{ 9f205f }{2.35} & \textcolor[HTML]{ b92045 }{2.57} & \textcolor[HTML]{ a0205e }{2.36} & \textcolor[HTML]{ ba2044 }{2.58} & \textcolor[HTML]{ aa2054 }{2.44} \\
        10                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ ab2053 }{2.46} & \textcolor[HTML]{ b72047 }{2.56} & \textcolor[HTML]{ 992065 }{2.30} & \textcolor[HTML]{ b92045 }{2.57} & \textcolor[HTML]{ ad2051 }{2.47} \\
        11                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ fc2002 }{3.13} & \textcolor[HTML]{ a72057 }{2.42} & \textcolor[HTML]{ f4200a }{3.07} & \textcolor[HTML]{ d2202c }{2.78} \\
        12                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 9b2063 }{2.32} & \textcolor[HTML]{ a82056 }{2.42} & \textcolor[HTML]{ a1205d }{2.37} \\
        13                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ ff2000 }{3.16} & \textcolor[HTML]{ d2202c }{2.78} \\
        14                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ cd2031 }{2.74} \\
    \end{tabular}

    \vspace{0.2em}

    \begin{tabular}{c|cccccccccccccc}
        $k_1 \backslash k_2$ & 1                                & 2                                & 3                                & 4                                & 5                                & 6                                & 7                                & 8                                & 9                                & 10                               & 11                               & 12                               & 13                               & 14                               \\
        \hline
        1                    & \textcolor[HTML]{ 0020ff }{1.00} & \textcolor[HTML]{ 0120fd }{1.02} & \textcolor[HTML]{ 0920f5 }{1.13} & \textcolor[HTML]{ 0a20f4 }{1.13} & \textcolor[HTML]{ 1020ee }{1.22} & \textcolor[HTML]{ 0b20f3 }{1.15} & \textcolor[HTML]{ 1320eb }{1.26} & \textcolor[HTML]{ 0f20ef }{1.20} & \textcolor[HTML]{ 1120ed }{1.23} & \textcolor[HTML]{ 0f20ef }{1.21} & \textcolor[HTML]{ 1620e8 }{1.30} & \textcolor[HTML]{ 0d20f1 }{1.18} & \textcolor[HTML]{ 1720e7 }{1.31} & \textcolor[HTML]{ 1220ec }{1.25} \\
        2                    &                                  & \textcolor[HTML]{ 2b20d3 }{1.58} & \textcolor[HTML]{ 2020de }{1.43} & \textcolor[HTML]{ 2120dd }{1.45} & \textcolor[HTML]{ 3020ce }{1.64} & \textcolor[HTML]{ 2320db }{1.48} & \textcolor[HTML]{ 3820c6 }{1.75} & \textcolor[HTML]{ 2d20d1 }{1.61} & \textcolor[HTML]{ 3420ca }{1.70} & \textcolor[HTML]{ 2f20cf }{1.63} & \textcolor[HTML]{ 4020be }{1.86} & \textcolor[HTML]{ 2a20d4 }{1.57} & \textcolor[HTML]{ 4220bc }{1.90} & \textcolor[HTML]{ 3520c9 }{1.72} \\
        3                    &                                  &                                  & \textcolor[HTML]{ 5220ac }{2.11} & \textcolor[HTML]{ 2f20cf }{1.63} & \textcolor[HTML]{ 4320bb }{1.90} & \textcolor[HTML]{ 3220cc }{1.67} & \textcolor[HTML]{ 5020ae }{2.07} & \textcolor[HTML]{ 4120bd }{1.87} & \textcolor[HTML]{ 4a20b4 }{2.00} & \textcolor[HTML]{ 4320bb }{1.90} & \textcolor[HTML]{ 5e20a0 }{2.26} & \textcolor[HTML]{ 3c20c2 }{1.81} & \textcolor[HTML]{ 62209c }{2.32} & \textcolor[HTML]{ 4d20b1 }{2.03} \\
        4                    &                                  &                                  &                                  & \textcolor[HTML]{ 5a20a4 }{2.22} & \textcolor[HTML]{ 4520b9 }{1.93} & \textcolor[HTML]{ 3320cb }{1.69} & \textcolor[HTML]{ 5320ab }{2.11} & \textcolor[HTML]{ 4320bb }{1.90} & \textcolor[HTML]{ 4d20b1 }{2.04} & \textcolor[HTML]{ 4520b9 }{1.93} & \textcolor[HTML]{ 61209d }{2.31} & \textcolor[HTML]{ 3e20c0 }{1.83} & \textcolor[HTML]{ 662098 }{2.37} & \textcolor[HTML]{ 4f20af }{2.07} \\
        5                    &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 8c2072 }{2.88} & \textcolor[HTML]{ 3f20bf }{1.85} & \textcolor[HTML]{ 6a2094 }{2.42} & \textcolor[HTML]{ 5420aa }{2.14} & \textcolor[HTML]{ 63209b }{2.33} & \textcolor[HTML]{ 5720a7 }{2.17} & \textcolor[HTML]{ 7f207f }{2.71} & \textcolor[HTML]{ 4e20b0 }{2.06} & \textcolor[HTML]{ 862078 }{2.80} & \textcolor[HTML]{ 662098 }{2.37} \\
        6                    &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 63209b }{2.33} & \textcolor[HTML]{ 5620a8 }{2.15} & \textcolor[HTML]{ 4520b9 }{1.93} & \textcolor[HTML]{ 5020ae }{2.08} & \textcolor[HTML]{ 4720b7 }{1.96} & \textcolor[HTML]{ 652099 }{2.36} & \textcolor[HTML]{ 4020be }{1.87} & \textcolor[HTML]{ 6a2094 }{2.43} & \textcolor[HTML]{ 5220ac }{2.11} \\
        7                    &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ b4204a }{3.41} & \textcolor[HTML]{ 5f209f }{2.27} & \textcolor[HTML]{ 70208e }{2.50} & \textcolor[HTML]{ 62209c }{2.32} & \textcolor[HTML]{ 91206d }{2.95} & \textcolor[HTML]{ 5820a6 }{2.18} & \textcolor[HTML]{ 992065 }{3.06} & \textcolor[HTML]{ 73208b }{2.54} \\
        8                    &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 8d2071 }{2.90} & \textcolor[HTML]{ 60209e }{2.28} & \textcolor[HTML]{ 5420aa }{2.14} & \textcolor[HTML]{ 7b2083 }{2.65} & \textcolor[HTML]{ 4c20b2 }{2.02} & \textcolor[HTML]{ 82207c }{2.74} & \textcolor[HTML]{ 63209b }{2.32} \\
        9                    &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ ac2052 }{3.31} & \textcolor[HTML]{ 5d20a1 }{2.25} & \textcolor[HTML]{ 892075 }{2.84} & \textcolor[HTML]{ 5420aa }{2.12} & \textcolor[HTML]{ 91206d }{2.94} & \textcolor[HTML]{ 6d2091 }{2.46} \\
        10                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 93206b }{2.97} & \textcolor[HTML]{ 7e2080 }{2.69} & \textcolor[HTML]{ 4e20b0 }{2.05} & \textcolor[HTML]{ 852079 }{2.78} & \textcolor[HTML]{ 652099 }{2.36} \\
        11                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ ea2014 }{4.14} & \textcolor[HTML]{ 62209c }{2.32} & \textcolor[HTML]{ af204f }{3.34} & \textcolor[HTML]{ 81207d }{2.73} \\
        12                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ 862078 }{2.79} & \textcolor[HTML]{ 7a2084 }{2.64} & \textcolor[HTML]{ 5d20a1 }{2.26} \\
        13                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ ff2000 }{4.41} & \textcolor[HTML]{ 852079 }{2.79} \\
        14                   &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  &                                  & \textcolor[HTML]{ b4204a }{3.41} \\
    \end{tabular}

    \caption{Die durchschnittliche Laufzeit von Pollards Rho-Algorithmus (oben) und berechnete Werte für die erwartete Laufzeit (unten), für $M = 2$ und $1 \le k_1 \le k_2 \le 14$. }
    \label{fig:measurements-m2}
\end{figure}

Um zu demonstrieren, dass Satz \ref{theorem:lki-asymp} das Laufzeitverhalten von Pollards Rho-Algorithmus gut beschreibt, wurden Laufzeitmessungen für $M = 1$ und $M = 2$ durchgeführt. Als Testzahlen wurden 192-Bit-Zahlen verwendet, bei denen jeder Primfaktor größer als $2^{22}$ ist und ein Primfaktor kleiner als $2^{23}$ ist. Die Größe der Primfaktoren nach unten zu beschränken ist sinnvoll, da die Laufzeit der Rho-Methode sonst sehr kurz wäre und die Messergebnisse durch Dinge wie den Aufwand der Laufzeitmessung selbst verfälscht werden würden. Es ist auch sinnvoll, dass die Testzahlen einen kleinen Primfaktor enthalten, da die Laufzeit sonst sehr groß wäre. Es wurden jeweils $2^{14}$ Testzahlen verwendet. Die mittlere Laufzeit und Werte von (\ref{eq:lki-asymp}) zum Vergleich sind in den Abbildungen \ref{fig:measurements-m1} und \ref{fig:measurements-m2} dargestellt. Sowohl die Werte der Formel als auch die Messdaten wurden skaliert, sodass bei $k = 1$ bzw. $k_1 = k_2 = 1$ der Wert 1 steht. Der Code für die Laufzeitmessungen ist unter \href{https://github.com/finn-rudolph/rhok}{\texttt{https://github.com/finn-rudolph/rhok}} verfügbar.

\subsection{Eine Maschine}

Man sieht, dass der Verlauf der Laufzeit von Formel (\ref{eq:lki-asymp}) widergespiegelt wird. Beispielsweise werden hohe Werte bei Primzahlen und niedrige Werte bei Zahlen mit vielen verschiedenen Primfaktoren (z.B. 24) angenommen.

Es fällt allerdings auf, dass die Laufzeit bei allen Werten von $k$ im Verhältnis zur Laufzeit bei $k = 1$ geringer als erwartet ist. Eine Erklärung dafür ist, dass der Aufwand der Berechnung von $\gcd(n, x_i - x_j)$ in der Rho-Methode vernachlässigt wurde. Obwohl, wie in Abschnitt \ref{sec:pollards-rho-method} beschreiben, die Optimierung aus \cite{bre80} verwendet wurde, um diesen Aufwand zu amortisieren, macht er immer noch einen relevanten Teil aus. Dadurch fällt der größere Aufwand der Berechnung von $x^{2k}$ für größere $k$ relativ gesehen weniger ins Gewicht.

An den Messergebnissen ist noch eine weitere Vereinfachung in der Analyse erkennbar. Wenn man die Laufzeit und Werte von (\ref{eq:lki-asymp}) bei $k = 8, 16, 32$ mit nahe gelegenen Werten vergleicht, beobachtet man, dass die Laufzeit im Verhältnis kleiner ist. Beispielsweise ist die Laufzeit bei $k = 16$ geringer als bei $k = 15$, der Wert von (\ref{eq:lki-asymp}) jedoch höher, und die Laufzeit bei $k = 32$ ist nahezu gleich der bei $k = 30$, wohingegen der Wert von (\ref{eq:lki-asymp}) deutlich größer ist. Das könnte daran liegen, dass der Aufwand zur Berechnung von $x^{2k}$ in der Praxis von der Anzahl an Einsen in der Binärdarstellung von $k$ abhängt. In der Implementierung wurde Square-and-Multiply zur Berechnung von Potenzen verwendet.

\subsection{Zwei Maschinen}

Auch hier wird das grundsätzliche Verhalten der Laufzeit durch (\ref{eq:lki-asymp}) reflektiert. Die Aussage von Satz \ref{theorem:optimal-k-m2} wird bestätigt, und es gibt zumindest für $1 \le k_1 \le k_2 \le 14$ kein Paar $k_1, k_2$ mit einer geringeren Laufzeit als $k_1 = k_2 = 1$. Da die Laufzeit für größere $k_1, k_2$ tendenziell zu steigen scheint, wird die Vermutung aufgestellt, dass $k_1 = k_2 = 1$ optimal ist.

\section{Fazit}

Zur Beantwortung der Frage nach der optimalen Wahl des Parameters $k$ konnten in dieser Arbeit grundlegende Formeln und Methoden entwickelt werden. Unter üblichen Annahmen über Pollards Rho-Algorithmus wurde eine Formel für die erwartete Laufzeit in Abhängigkeit der $k_i \ (1 \le i \le M)$ aufgestellt. Die damit erzielten Ergebnisse für $M = 1$ und $M = 2$ werden von Laufzeitmessungen unterstützt. Auch zeigen die Messungen, dass Formel (\ref{eq:lki-asymp}) zum Vergleich der Laufzeit bei verschiedenen Werten von $k$ geeignet ist. Für eine vollständige Beantwortung der Frage sind allerdings noch weitere Schritte nötig. Der Fall $M = 2$ müsste vollständig geklärt werden, und $M \ge 3$ wurde in dieser Arbeit noch nicht behandelt.

Darüber hinaus stellt sich die Frage, ob es sinnvoll ist, nach der Wahl von $k$-Werten während der gesamten Ausführung des Algorithmus bei diesen zu bleiben. Möglicherweise ist es besser, dass eine Maschine nach längerer Zeit mit einem bestimmten Wert von $k$ diesen aufgibt und mit einem anderen $k$ weitermacht.

\newpage
\printbibliography

\end{document}