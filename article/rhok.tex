\documentclass[a4paper, 10pt, ngerman]{article}

\usepackage[algoruled, nosemicolon]{algorithm2e}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[ngerman]{babel}
\usepackage[backend=biber, style=apa]{biblatex}
\usepackage[left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.cm]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{mathtools}
\usepackage[onehalfspacing]{setspace}
\usepackage{sectsty}
\usepackage[inkscapeformat=pdf]{svg}

\allsectionsfont{\sffamily}

\title{\sffamily{\textbf{Parametrisierung von Pollards Rho-Methode}}}
\author{Finn Rudolph}
\date{27.01.2024}

\addbibresource{rhok.bib}

\renewcommand{\thealgocf}{}

\newcommand{\C}{\mathbb{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\renewcommand{\P}{\mathbb{P}}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Satz}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Annahme}

\begin{document}

\maketitle

\section*{Projektüberblick}

\tableofcontents

\section{Zusammenfassung}

\section{Motivation und Fragestellung}

Während für Rekordfaktorisierungen mittlerweile ausschließlich das Zahlkörpersieb verwendet wird, bleibt Pollards Rho-Algorithmus einer schnellsten Algorithmen zur Faktorisierung von Zahlen bis ca. $2^{64}$. Da Leistungssteigerungen bei modernen Computern häufig durch verbesserete Nebenläufigkeit (z. B. durch mehr Prozessorkerne) erzielt werden, ist es eine interessante Frage, wie Pollards Rho-Methode am besten parallel ausgeführt werden kann. Bevor die Fragestellung präzise formuliert werden kann, soll jedoch Pollards Rho-Methode erklärt werden.

\subsection{Pollards Rho-Methode}

Sei $n$ die zu faktorisierende Zahl und $f : \Z/n\Z \to \Z/n\Z$ mit $f : x \mapsto x^{2k} + 1$ für einen Parameter $1 \le k \in \N$. Man wähle einen zufälligen Anfangswert $x_0 \in \Z/n\Z$ und betrachte die Folge $(x_n)_{n \in \N}$ definiert durch $x_n = f(x_{n - 1})$ für einen Parameter $1 \le k \in \N$. Da $(x_n)_{n \in \N}$ über der endlichen Menge $\Z/n\Z$ definiert ist, ist die Folge ab einem bestimmten Punkt periodisch. Sei $p$ ein Primfaktor von $n$ und $\pi : \Z/n\Z \to \Z/p\Z$ die natürliche Projektion. Die Idee von Pollards Rho-Algorithmus ist, zwei Folgenglieder $x_i, x_j \in \Z/n\Z$ zu finden, sodass $x_i \ne x_j$ aber $\pi(x_i) = \pi(x_j)$. Dann ist nämlich $\gcd(n, x_i - x_j)$ ein echter Faktor von $n$. Nimmt man nun heuristisch an, dass die Periodenlänge von $(x_n)_{n \in \N}$ in $\Z/n\Z$ deutlich länger als die Periodenlänge in $\Z/p\Z$ ist, reicht es aus, $x_i, x_j$ mit $i \ne j$ zu finden, die kongruent modulo $p$ sind. Diese Annahme begründet sich darin, dass für den kleinsten Primfaktor $p \le \sqrt n$ gilt. Zum Finden solcher $x_i, x_j$ betrachten wir den funktionalen Graphen von $\pi(f)$, wobei $\pi(f)$ die Abbildung $f$ betrachtet in $\Z/p\Z$ ist.

\begin{definition}[Funktionaler Graph]
    Sei $X$ eine endliche Menge und $f: X \to X$ eine Abbildung. Der funktionale Graph von $f$, geschrieben $\gamma(f)$, ist der gerichtete Graph mit Knotenmenge $X$ und Kantenmenge $E$, wobei die Kante $(x, y) \in X \times X$ genau dann in $E$ liegt, wenn $f(x) = y$.
\end{definition}

\noindent Es ist leicht zu zeigen, dass jede Zusammenhangskomponente eines funktionalen Graphen aus einem Zyklus und an den Zyklusknoten gewurzelten Bäumen besteht. In $\gamma(f)$ betrachtet startet $(x_n)_{n \in \N}$ mit $x_0$ in einem Baum und "`läuft"' durch den Graphen, wobei immer die eindeutige von einem Knoten ausgehende Kante entlanggegangen wird. An der Wurzel des Baums von $x_0$ wird der Zyklus in der Zusammenhangskomponente von $x_0$ betreten, und ab genau diesem Punkt ist $(x_n)_{n \in \N}$ periodisch. Um $x_i, x_j$ mit $i \ne j$ und $\pi(x_i) = \pi(x_j)$ zu finden, wird Floyds Algorithmus zum Finden des Zyklus in der Zusammenhangskomponente von $\pi(x_0)$ in $\gamma(\pi(f))$ verwendet. Floyds Algorithmus macht sich zunutze, dass es ein $r \in \N, 1 \le r \ge 1$ mit $\pi(x_r) = \pi(x_{2r})$ geben muss. Für das minimale solcher $r$ gilt außerdem $r \le \mu(f, x_0) + \lambda(f, x_0)$, wobei $\mu(f, x_0)$ die Höhe von $x_0$ in seinem Baum und $\lambda(f, x_0)$ die Länge des Zyklus ist (\cite{knu98}, S. 7). Wir nennen $\nu(f, x_0) = \mu(f, x_0) + \lambda(f, x_0)$ die Rho-Länge von $x_0$ in $f$. Indem man die Folgen $(x_n)_{n \in \N}$ und $(x_{2n})_{n \in \N}$ gleichzeitig Glied für Glied berechnet, stößt man in maximal $\nu(f, x_0)$ Schritten auf gewünschte $x_i, x_j$. Das Überprüfen in jedem Schritt, ob $\pi(x_i) = \pi(x_{2i})$ geschieht natürlich nicht explizit, da $p$ unbekannt ist, aber implizit durch Berechnung von $\gcd(n, x_i - x_{2i})$.

\begin{algorithm*}
    $x \gets $ zufällige natürliche Zahl zwischen $0$ und $n - 1$ \;
    $y \gets x$ \;
    \While{\emph{\sc{true}}}
    {
        $x \gets x^{2k} + 1 \mod n$ \;
        $y \gets (y^{2k} + 1)^{2k} + 1 \mod n$ \;
        $g \gets \gcd(n, x - y)$ \;
        \If{$g \ne 1 \text{\emph{\textbf{ and }}} g \ne n$}
        {
            \Return{$g$} \;
        }
    }

    \caption{Pollards Rho-Algorithmus}
\end{algorithm*}

\noindent Die Analyse von Pollards Rho-Algorithmus erweist sich als schwierig, es ist bis dato keine rigorose Laufzeitanalyse bekannt. Stattdessen werden heuristische Annahmen getroffen. Anstatt der mittleren Anzahl an Iterationen von Floyds Algorithmus wird die mittlere Rho-Länge analysiert, mit der Annahme, dass sich diese zwei Werte für große $p$ nur um eine feste Konstante unterscheiden. Um die zentrale Annahme über Pollards Rho-Algorithmus zu formulieren, wird der Begriff einer asymptotischen Näherung benötigt.

\begin{definition}[Asymptotische Näherung]
    Eine Funktion $f : \R \to \R$ heißt genau dann asymptotische Näherung von einer Funktion $g : \R \to \R$, oder asymptotisch zu $g$, wenn
    \begin{align*}
        \lim_{x \to \infty} \frac {f(x)} {g(x)} = 1
    \end{align*}
    In diesem Fall schreiben wir $f \sim g$.
\end{definition}

Sei $A(n)$ die Menge der Abbildungen $\Z/n\Z \to \Z/n\Z$ für $n \in \N$. Über die Verteilung der Rho-Längen wird Folgendes angenommen.

\begin{assumption}
    Sei $f : x \mapsto x^{2k} + 1$ und $d = \gcd(p - 1, 2k)$. Seien $x_0 \in \Z/p\Z$ und $y_0 \in \Z/(p/(d - 1))\Z$ zufällig und $g \in A(p/(d - 1))$ zufällig. Dann gilt $\P(\nu(f, x_0) = m) \sim \P(\nu(g, y_0) = m)$ für $p \to \infty$.
\end{assumption}

\noindent In anderen Worten sagt Annahme 1, dass sich die Verteilung der Rho-Längen von $f : x \mapsto x^{2k} + 1$ wie bei einer zufälligen Funktion aus $A(p/(d - 1))$ verhält. Insbesondere verhält sich $x \mapsto x^2 + 1$ bezüglich der Rho-Längen wie ein zufällige Funktion $\Z/p\Z \to \Z/p\Z$. \cite{bp81} geben eine Begründung für Annahme 1.

Für $k = 1$ ist damit die erwartete Anzahl an Iterationen der while-Schleife asymptotisch zu $\sqrt{\pi p / 2}$ (\cite{knu98}, S. 8). Da die Berechnung des größten gemeinsamen Teilers $O(\ln n)$ Schritte benötigt, ist die erwartete Laufzeit des Algorithmus $O(\sqrt p \ln n)$. Durch eine einfache Modifikation können die Kosten des $\gcd$ amortisiert werden, sodass sich die Laufzeit auf $O(\sqrt p)$ verringert (\cite{bre80}). Damit ist pro Iteration also nur noch die Zeit zur Berechnung der $2k$-ten Potenzen von $x$ und $y$ relevant, was durchschnittlich in $3/2 \lg 2k$ Schritten möglich ist. Mit $\lg x$ wird der Logarithmus zur Basis 2 bezeichnet. Der Faktor $3/2$ in dieser Arbeit unwichtig und wird daher ignoriert.

\subsection{Parallelisierung der Rho-Methode}\label{sec:par}

Sei $M$ die Anzahl verfügbarer Maschinen. Eine "`Maschine"'  meint hier nicht zwingend einen Computer, sondern eine Ressource, auf der ein sequentielles Programm ausgeführt werden kann, was beispielsweise auch ein Prozessorthread sein kann. Die Rho-Methode lässt sich parallelisieren, indem $M$ Anfangswerte unabhängig voneinander zufällig gewählt werden und auf jeder der $M$ Maschinen Pollards Rho-Algorithmus ausgeführt wird, bis eine der Maschinen einen Faktor findet. Nun ergibt sich folgende Frage, die in dieser Arbeit behandelt werden soll: \emph{Wie wählt man den Parameter $k$ für jede Maschine optimal, um eine möglichst geringe Laufzeit zu erzielen?} Eine Zeiteinheit ist hier die Dauer einer Iteration im Fall $k = 1$, d.h. eine Maschine mit Paramter $k$ führt in $t$ Zeiteinheiten $\lfloor t / \lg 2k \rfloor$ Iterationen aus. Da es sich bei den Veränderungen in der Laufzeit durch Veränderung von $k$ um konstante Faktoren handelt, wird für den Vergleich wird die Laufzeit nicht $O$-Notation verwendet, sondern eine asymptotische Näherung für die erwartete Zahl an Zeiteinheiten bestimmt. Im Gegensatz zur $O$-Notation kann zwischen zwei Funktionen, die asymptotisch zueinander sind, für große $n$ kein konstanter Faktor liegen, sodass sich Veränderungen um konstante Faktoren sinnvoll vergleichen lassen.

Eine Zuordnung von $k$-Werten für $M$ Maschinen wird als Tupel $K = (k_1, k_2, \dots, k_M), 1 \le k_i \in \N$ geschrieben.  Wir bezeichnen mit $L_K(p)$ die erwartete Laufzeit des parallelen Pollard-Rho-Algorithmus mit $k$-Werten gegeben durch $K$ und fixiertem $\gcd(p - 1, 2k_i)$ für alle $1 \le i \le M$. Der Erwartungswert über alle Möglichkeiten von $\gcd(p - 1, 2k_i)$ wird erst in Abschnitt \ref{sec:optk} behandelt. Sei $h_i = p/(\gcd(p - 1, 2k_i) - 1)$. Mit Annahme 1 gilt
\begin{align*}
    L_K(p) = \E \bigg ( \min_{i = 1}^M X_i \bigg )
\end{align*}
wobei $X_i$ die gleichverteilte Zufallsvariable über $A(h_i) \times \Z/h_i\Z$ mit $X_i(f, x_0) = \nu(f, x_0)$ ist. Eine Schwierigkeit in der Herleitung einer Formel für $L_K(p)$ ist, dass die Rho-Längen der $i$-ten und $j$-ten Maschine nicht unabhängig sind, wenn $k_i = k_j$, da sich die $i$-te und $j$-te Maschine in diesem Fall im gleichen funktionalen Graphen bewegen. Wenn beispielsweise der Startwert der $i$-ten Maschine fixiert wird, ist bereits klar, dass die Rho-Länge der $j$-ten Maschine größer gleich der Rho-Länge der $i$-ten Maschine sein wird, wenn der Startwert ein Vorfahre des Startwerts der $i$-ten Maschine in einem Baum von $\gamma(f)$ ist. Daher werden im Folgenden die Fälle abhängiger und unabhängiger Maschinen unterschieden.


\section{Eine Formel für den Fall unabhängiger Maschinen}

// Make the argument more streamlined, clear and rigorous

In diesem Abschnitt wird eine Formel für $L_K(p)$ hergleitet, die im Fall paarweise verschiedener $k$-Werte gilt. Wenn $k_i \ne k_j$, wird angenommen, dass die Rho-Längen der $i$-ten und $j$-ten Maschine als Zufallsvariablen betrachtet stochastisch unabhängig sind.

Sei $h_i = p/(\gcd(p - 1, 2k_i) - 1)$ und $t_i$ die Anzahl an Zeiteinheiten, nach der bei der $i$-ten Maschine erstmals eine Kollision auftritt. Maschine $i$ führt in $t$ Zeiteinheiten $\lceil t / \lg 2k_i \rceil$ Iterationen durch. Nach Annahme 1 gilt $\P(t_i \ge t) = \P(\nu(f, x_0) \ge \lceil t / \lg 2k_i \rceil)$ für eine zufällig gewählte Funktion $f \in A(h_i)$ und ein zufälliges $x_0 \in \Z/h_i\Z$. Für eine zufällige Funktion $f \in A(h_i)$ gilt, dass die Wahrscheinlichkeit einer Kollision im $i$-ten Schritt $i/h_i$ ist, wenn in den ersten $i-1$ Schritten keine Kollision aufgetreten ist, da jeder der $h_i$ möglichen Werte gleich wahrscheinlich ist und $i$ von ihnen zu einer Kollision führen. Folglich gilt
\begin{align*}
    \P(t_i \ge t) = \P(\nu(f, x_0) \ge \lceil t / \lg 2k_i \rceil) = \prod_{j = 0}^{\lceil t / \lg k_i - 1 \rceil} \bigg (1 - \frac {j} {h_i} \bigg )
\end{align*}
Nun wird Taylors Näherung $1 + x \approx \exp x$, wenn $|x|$ klein, für $1 - j/h_i$ verwendet. Da in allen praktischen Fällen $t/\lg 2k_i$ deutlich kleiner als $h_i$ ist (nach obiger Diskussion erwarten wir $t/\lg 2k_i \approx \sqrt{h_i}$), ist dies vertretbar.
\begin{align*}
    \prod_{j = 0}^{\lceil t / \lg k_i - 1 \rceil} \bigg (1 - \frac {j} {h_i} \bigg )
    \approx \exp \Bigg (-\sum_{j = 0}^{\lceil t / \lg k_i - 1 \rceil} \frac j {h_i} \Bigg )
    = \exp \Bigg (- \frac {\lceil t / \lg 2k_i \rceil (\lceil t / \lg 2k_i \rceil - 1)} {2h_i} \Bigg )
\end{align*}
Im Folgenden werden die Gaußklammern weggelassen, da sie asymptotisch nichts ändern und $t/\lg2k_i \cdot (t/\lg2k_i - 1)$ durch $(t/\lg2k_i)^2$ angenähert.
\begin{align}
    \P(t_i \ge t)
    \approx \exp \Bigg (- \frac {\lceil t / \lg 2k_i \rceil (\lceil t / \lg 2k_i \rceil - 1)} {2h_i} \Bigg )
    \approx \exp \Bigg ( - \frac {t^2} 2 \cdot \frac 1{h_i \lg^2 2k_i} \Bigg ) \label{ptiget}
\end{align}
Sei $t_{\min} = \min_{i = 1}^M t_i$. Die Wahrscheinlichkeit, dass bei mindestens einer Maschine bei Zeitpunkt $t$ eine Kollision auftritt, kann wegen $t / \lg 2k_i$ deutlich kleiner als $h_i$ und der Unabhängigkeit der Maschinen durch $\sum_{i = 1}^M t/h_i\lg2k_i$ angenähert werden. Mit (\ref{ptiget}) schließt man
\begin{align*}
    \P(t_{\min} = t)
     & = \prod_{i = 1}^M \P(t_i \ge t) \cdot \sum_{i = 1}^M \frac {t} {h_i\lg2k_i}                                                            \\
     & \approx \prod_{i = 1}^M \exp \Bigg ( - \frac {t^2} 2 \cdot \frac 1{h_i \lg^2 2k_i} \Bigg ) \cdot \sum_{i = 1}^M \frac {t} {h_i\lg2k_i} \\
     & = \exp \Bigg ( - \frac {t^2} 2 \sum_{i = 1}^M \frac 1{h_i \lg^2 2k_i} \Bigg ) \cdot \sum_{i = 1}^M \frac {t} {h_i\lg2k_i}              \\
\end{align*}
Um nun eine Formel für den Erwartungswert von $t_{\min}$ zu erhalten, wird $\sum_{a = 1}^p t \cdot \P(t_{\min} = t)$ durch $\int_{0}^\infty t \cdot \P(t_{\min} = t) \; dt$ angenähert, was wegen der schnellen Konvergenz von $e^{-t^2} \to 0$ wenn $t \to \infty$ vertetbar ist.
\begin{align}
    L_K(p)
     & = \Bigg ( \sum_{i = 1}^M \frac 1 {h_i \lg 2k_i} \Bigg ) \int_{0}^{\infty} t^2 \exp \Bigg (- \frac {t^2} 2 \sum_{i = 1}^M \frac 1 {h_i \lg^2 2k_i} \Bigg ) \ dt \nonumber \\
     & = \Bigg ( \sum_{i = 1}^M \frac 1 {h_i \lg 2k_i} \Bigg ) \sqrt {\pi/2} \Bigg (\sum_{i = 1}^M \frac 1 {h_i \lg^2 2k_i} \Bigg )^{-3/2}
    \label{lkp}
\end{align}
Zur Auswertung des Integrals wurde die Tabelle in Wikipedia: \cite{gint} verwendet. Auch wenn die Herleitung aufgrund der vielen Näherungen krude scheint, erklärt sie gut das Laufzeitverhalten im Fall unabhängiger Maschinen. Setzt man beispielsweise $M = 1$ und $k_1 = 1$, erhält man $\sqrt{\pi p / 2}$, wie in \cite{pol75}. Für $M = 1$ und beliebiges $k_1$ erhält man $\sqrt{\pi p / 2} \cdot \lg^2 2k_1 / \sqrt{\gcd(p-1, 2k_1) - 1}$. Daraus folgt, dass die Anzahl an Iterationen im Fall einer Maschine um einen Faktor $1/\sqrt{\gcd(p - 1, 2k) - 1}$ im Vergleich zu $k = 1$ reduziert wird. Dieses Ergebnis erhielten auch \cite{bp81}.

\section{Die erwartete minimale Rho-Länge bei mehreren Anfangswerten}

Um $L_K(p)$ zu bestimmen, wenn $k_i = k_j$ für $i \ne j$ gilt, muss die Abhängigkeit der Rho-Längen der $i$-ten und $j$-ten Maschinen berücksichtigt werden. Denn setzt man beispielsweise $M = 2$ und $k_1 = k_2 = 1$ in (\ref{lkp}) ein, erhält man eine erwartete Laufzeit von $\sqrt {\pi p / 4}$. In diesem Abschnitt wird allerdings gezeigt, dass unter Berücksichtigung der Abhängigkeit $25/32 \cdot \sqrt{\pi p / 2}$ Schritte benötigt werden, und letzterer Wert wird von Experimenten unterstützt. Der Fall abhängiger Maschinen hat sich als weitaus schwieriger herausgestellt und es wurde keine allgemeine Formel gefunden. Jedoch konnte der Fall $M = 2, k_1 = k_2$ gelöst werden. Für den Fall $k_1 = k_2 = \dots = k_M$, sei $k = k_1$ und $h = \gcd(p - 1, 2k)$. Nach Annahme 1 die Verteilung der Rho-Längen von $f : x \mapsto x^{2k} + 1$ für $p \to \infty$ asymptotisch zur Verteilung der Rho-Längen zufälliger Elemente in $A(h)$. Da sich die $M$ Maschinen im Fall $k_1 = k_2 = \dots = k_M$ alle im gleichen funktionalen Graphen bewegen, reduziert sich das Problem der Bestimmung einer asymptotischen Näherung von $L_{k, k, \dots, k}$ auf folgende Frage: \emph{Für $n \in \N$, gegeben ein zufälliges Element $f$ aus $A(n)$ und $M$ zufällige Elemente $x_{i, 0} \in Z/n\Z \; (1 \le i \le M)$, was ist der Erwartungswert von $\min_{i = 1}^M \nu(f, x_{i, 0})$?}

\subsection{Theoretischer Hintergrund: Erzeugende Funktionen}

Der grundlegende Ansatz zur Beantwortung obiger Frage für $M = 2$ ist, die Summe der minimalen Rho-Längen über alle Elemente von $A(p)$ und Paare an Anfangswerten zu bestimmen. Dafür soll eine erzeugende Funktion $\Psi(x, w)$ hergeleitet werden, in der die Variable $x$ die Größe des Graphen und die Variable $w$ die minimale Rho-Länge markiert. Dann gilt nämlich
\begin{align*}
    L_{1, 1}(n) = \frac {n!}{n^{n + 2}} [x^n] \Bigg (\frac {\partial} {\partial w} \Psi(x, w) \Bigg ) \Bigg \vert_{w = 1}
\end{align*}
wobei $[x^n]$ den $n$-ten Koeffizienten in der Reihenentwicklung des nachstehenden Terms bezeichnet.

Da funktionale Graphen beschriftet sind, werden stets erzeugende Funktionen von exponentiellem Typ (EF) verwendet. Folgende Komponenten eines funktionalen Graphen werden als Grundlage verwendet, um einen funktionalen Graphen zu konstruieren (\cite{fo90}, S. 333).
\begin{align*}
    T(x) = x \exp T(x) \quad (\text{Baum}) \qquad\qquad C(x) = \ln \frac {1} {1 - x} \quad (\text{Zyklus})
\end{align*}
Ein funktionaler Graph ist eine Menge an Zyklen von Bäumen, also ist die EF für funktionale Graphen
\begin{align*}
    F(x) = \exp C(T(x)) = \exp \ln \frac 1 {1 - T(x)} = \frac 1 {1 - T(x)}
\end{align*}

Für die Koeffizienten von $((\partial / \partial w) \Psi(x, w)) |_{w = 1}$ wird später eine asymptotische Näherung bestimmt. Dafür wird folgender Satz von \cite{fo90} verwendet, der hier der Vollständigkeit halber erneut formuliert wird.

\begin{theorem}[\cite{fo90}]
    Sei $f(x)$ eine Funktion, die analytisch in
    \begin{align*}
        D = \{x : |x| \le s_1, \arg(x - s) > \pi/2 - \eta \}
    \end{align*}
    ist, für positive reelle Zahlen $s, s_1, \eta$ mit $s_1 > s$. Man nehme an, dass
    \begin{align*}
        f(x) \sim \sigma \bigg ( \frac 1 {1 - x/s} \bigg )
    \end{align*}
    wenn $x \to s$ in $D$, wobei $\sigma(x) = x^\alpha \ln^\beta x$ und $\alpha \notin \{0, -1, -2, \dots\}$. Dann gilt für die Koeffizienten der Taylorreihe von $f$
    \begin{align*}
        [x^n]f(x) \sim s^{-n} \frac {\sigma(n)}{n\Gamma(\alpha)}
    \end{align*}
\end{theorem}

\subsection{Der Fall zweier Anfangswerte}\label{sec:start2}

// Sagen dass wir erst nur den für a und b relevanten Teil des Graphen konstruieren.

\begin{theorem}
    Sei $A(n)$ die Menge der Abbildungen $\Z/n\Z \to \Z/n\Z$. Dann gilt
    \begin{align*}
        \frac 1 {n^{n + 2}} \sum_{f \in A(n)} \; \sum_{a \in \Z/n\Z} \; \sum_{b \in \Z/n\Z} \min(\nu(f, a), \nu(f, b)) \sim \frac {25} {32} \sqrt{\pi n / 2}
    \end{align*}
\end{theorem}

\begin{proof}
    // Maybe bezug von $\Psi$ zu obiger Summe noch einmal klar machen


    Seien $a$ und $b$ die zwei Startknoten und $\Psi(x, w)$ wie bereits definiert. Zur Bestimmung von $\Psi(x, w)$ unterscheiden wir drei disjunkte Fälle, die in Abbildung 1 dargestellt sind. Die Graphen werden grundsätzlich so konstruiert, dass $\nu(f, a) \le \nu(f, b)$, und wenn $\nu(f, a) < \nu(f, b)$, wird mit einem Faktor 2 für das mögliche Vertauschen von $a$ und $b$ multipliziert.

    \begin{figure}
        \begin{tabular}{ccc}
            \includesvg[width=150pt]{pics/alpha} & \includesvg[width=150pt]{pics/beta} & \includesvg[width=150pt]{pics/gamma} \\
            ($\alpha$)                           & ($\beta$)                           & ($\gamma$)
        \end{tabular}
        \caption{Die drei Fälle für die Bestimmung von $\Psi(x, w)$. Die Kanten stellen keine einzelne Kante dar, sondern einen beliebig langen (und möglicherweise leeren) Pfad. Beispielsweise steht die Kurve $r$ in ($\alpha$) für den Zyklus in dem Zusammenhangskomponenten von $a$.}
    \end{figure}

    \textbf{Fall 1.} (\emph{$a$ und $b$ liegen in unterschiedlichen Zusammenhangskomponenten.}) Dieser Fall wird erneut in die Fälle $\lambda(f, b) \le \nu(f, a)$ und $\lambda(f, b) > \nu(f, a)$ unterteilt. Die erzeugende Funktion für den ersten Fall ist
    \begin{align*}
        \alpha_1(x, w) = \frac {x^2w(1 + x^2w)} {(1 - x^2w)^3} \cdot \Bigg (1 + \frac {2x} {1 - x} \Bigg ) = \frac {x^2w(1 + x)(1 + x^2w)} {(1 - x^2w)^3(1 - x)}
    \end{align*}
    In diesem Fall ist es möglich, zuerst zwei $\rho$-Graphen mit gleicher Größe zu erzeugen und anschließend den Pfad von $b$ zu seinem Zyklus zu verlängern. Ein $\rho$-Graph ist ein Zusammenhangskomponent in Abbildung ($\alpha$), d.h. ein Zyklus mit einem Pfad anhängend. Es gibt genau $n! \cdot n$ $\rho$-Graphen mit $n$ Knoten, da es für jede Permutation der Knoten $n$ Möglichkeiten für die Größe des Zyklus gibt. Folglich gibt es für gerade $n$ genau $n! \cdot n^2/2$ Paare an $\rho$-Graphen, die beide $n/2$ Knoten besitzen. Die erzeugende Funktion von Paaren an $\rho$-Graphen gleicher Größe ist also
    \begin{align*}
        \sum_{n = 0}^\infty x^n \cdot \frac {n^2} 4 \cdot \frac {1 + (-1)^n} 2 = \frac {x^2(1 + x^2)} {(1 - x^2)^3}
    \end{align*}
    Um die halbe Anzahl an Knoten mit $w$ zu markieren, ersetze man $x$ durch $x \sqrt w$ und erhält $x^2w(1 + x^2w) / (1 - x^2w)^3$. Das erklärt den ersten Faktor in $\alpha_1(x, w)$. Nun gibt es zwei Möglichkeiten: Wird der Pfad von $b$ zu seinem Zyklus ($u$ in Abbildung 1 ($\alpha$)) nicht verlängert, gilt $\nu(f, a) = \nu(f, b)$, es ergibt sich durch Vertauschen von $a$ und $b$ also keine neue Möglichkeit. Wird hingegen ein Pfad von Länge $\ge 1$ angehängt, dessen erzeugende Funktion $x/(1 - x)$ ist, ergibt sich eine weitere Möglichkeit durch Vertauschen von $a$ und $b$.

    Im zweiten Fall ist die erzeugende Funktion
    \begin{align*}
        \alpha_2(x, w) = 2 \cdot \frac {x^2w} {(1 - x^2w)^2} \cdot  \frac x {1 - x} \cdot \frac {1}{1 - x} = \frac {2x^3w} {(1 - x^2w)^2 (1 - x)^2}
    \end{align*}
    Der Faktor $x^2w$ repräsentiert die zwei Knoten, an denen $a$ und $b$ jeweils ihren Zyklus betreten, und der Knoten von $a$ ist mit $w$ markiert. Mit $1 / (1 - x^2w)^2$ erhält man vier Pfade $r, y, s, z$, sodass die Länge von $r$ gleich der Länge von $y$ und die Länge von $s$ gleich der Länge von $z$ ist. Die Summe der Längen von $r$ und $s$ wird von $w$ markiert. $r$ und $s$ werden wie in Abbildung 1 ($\alpha$) für den Zusammenhangskomponenten von $a$ verwendet. Damit ist der Exponent von $w$ genau die Rho-Länge von $a$. Der Zyklus von $b$ besteht aus $y, z$ und einem Pfad von Länge $\ge 1$, sodass $\lambda(f, b) > \nu(f, a)$ gilt. Der Term $1 / (1 - x)$ steht für den Pfad von $b$ zum Zyklus.

    Die erzeugende Funktion für Fall 1 ist also
    \begin{align*}
        \alpha(x, w)
        = \alpha_1(x, w) + \alpha_2(x, w)
        = \frac {x^2w(1 + 2x - x^2 + x^2w - 2x^3w - x^4w)} {(1 - x^2w)^3(1 - x)^2}
    \end{align*}

    \textbf{Fall 2.} (\emph{$a$ und $b$ liegen im gleichen Baum und ihr kleinster gemeinsamer Vorfahre ist nicht die Wurzel.}) Anders formuliert: Betrachtet man die Pfade, die $a$ und $b$ durch wiederholtes Anwenden von $f$ in $\gamma(f)$ ablaufen, treffen diese sich nicht erstmals in einem Zyklusknoten. Die erzeugende Funktion lautet
    \begin{align*}
        \beta(x, w)
        = xw \cdot \frac {xw} {1 - xw} \cdot \frac {1} {1 - xw} \cdot \frac {1} {1 - x^2w} \cdot \Bigg (1 + \frac {2x} {1 - x} \Bigg )
        = \frac {x^2w^2(1 + x)} {(1 - xw)^2(1 - x^2w)(1 - x)}
    \end{align*}
    Der Zyklusknoten, an dem der Baum von $a$ und $b$ anhängt, wird durch $xw$ repräsentiert. Der Pfad $s$ in Abbildung 1 ($\beta$) muss mindestens Länge 1 haben, da der kleinste gemeinsame Vorfahre von $a$ und $b$ sonst die Wurzel wäre, was den Faktor $xw/(1 - xw)$ erklärt. Der Faktor $1/(1 - xw)$ steht für den Zyklus $r$. Mit $1/(1 - x^2w)$ werden zwei gleich lange Pfade erzeugt, deren Länge durch $w$ markiert wird. Ein Pfad ist $t$ in Abbildung 1 ($\beta$), und der andere ist ein Teil von $u$. Nun gibt es wie in Fall 1 wieder die Option, $u$ echt zu verlängern und so einen Faktor 2 für die mögliche Vertauschung von $a$ und $b$ zu erhalten, oder ihn zu lassen, wobei es wegen Symmetrie nur eine Möglichkeit gibt.

    \textbf{Fall 3.} (\emph{$a$ und $b$ liegen in verschiedenen Bäumen oder die Wurzel ist kleinster gemeinsamer Vorfahre.}) Die erzeugende Funktion ist hier
    \begin{align*}
        \gamma(x, w)
        = xw \cdot \frac {1} {(1 - xw)^2} \cdot \frac {1} {1 - x^2w} \cdot \Bigg (1 + \frac {2x}{1 - x} \Bigg )
        = \frac {xw(1 + x)} {(1 - xw)^2(1 - x^2w)(1 - x)}
    \end{align*}
    $xw$ stellt den Zyklusknoten da, an dem der Baum von $a$ anhängt. Der Term $1/(1 - xw)^2$ repräsentiert die beiden Pfade von der Wurzel von $a$ zur Wurzel von $b$ und zurück ($r$ und $s$ in Abbildung 1 ($\gamma$)). Ähnlich wie in Fall 2 ist der Term $1/(1 - x^2w)$ ein Paar an gleich langen Pfaden, deren Länge von $w$ markiert wird. Einer der Pfade ist $u$ in Abbildung 1 ($\gamma$) und der andere ein Teil von $t$. Auch hier kann man die Länge von $t$ Zyklus unverändert lassen, in diesem Fall gibt es eine Möglichkeit, oder einen Pfad von Länge $\ge 1$ hinzufügen, sodass es zwei Möglichkeiten wegen Vertauschung von $a$ und $b$ gibt.

    Ein funktionaler Graph besteht natürlich nicht nur aus einem Zyklus und den Pfaden von $a$ und $b$ zum Zyklus. Von jedem Knoten kann ein Baum ausgehen und es kann noch weitere Zusammenhangskomponenten geben. Durch Erstetzen von $x$ durch $T(x)$ und Hinzufügen einer beliebigen Menge weiterer Zusammenhangskomponenten erhält man also $\Psi(x, w)$.
    \begin{align*}
        \Psi(x, w)
         & = (\alpha(T(x), w) + \beta(T(x), w) + \gamma(T(x), w)) \cdot \exp C(T(x)) \\
         & = \frac {\alpha(T(x), w) + \beta(T(x), w) + \gamma(T(x), w)} {1 - T(x)}
    \end{align*}
    Damit erhalten wir
    \begin{align*}
        \psi(x) = \Bigg (\frac {\partial} {\partial w} \Psi(x, w) \Bigg ) \Bigg \vert_{w = 1} = \frac {T(x)(1 + 2T(x) + 2(T(x))^2)(1 + 5T(x) + 3(T(x))^2 + (T(x))^3)} {(1 - T(x))^6(1 + T(x))^3}
    \end{align*}
    Nun soll die Methode von \cite{fo90} verwendet werden, um eine asymptotische Abschätzung für die Koeffizienten der Reihe von $\psi(x)$ zu erhalten. Nach \cite{fo90}, S. 334, Proposition 1 ist die betragsmäßig (in $\C$) kleinste Singularität von $T(x)$ bei $x = e^{-1}$ und es gilt
    \begin{align*}
        T(x) = 1 - \sqrt{2}\cdot \sqrt {1 - ex} - O(1 - ez)
    \end{align*}
    für $x \to e^{-1}$. $\psi(x)$ hat keine betragsmäßig kleineren Singularitäten, denn wenn $1 - T(x) = 0$, rechnet man leicht nach, dass $x = e^{-1}$ gilt, und wenn $1 + T(x) = 0$, gilt $x = -e$. Es wird nun Satz 1 mit $s = e^{-1}$ verwendet. Wenn $x \to e^{-1}$, gilt
    \begin{align*}
        \psi(x)
         & \sim \frac {T(e^{-1})(1 + 2T(e^{-1}) + 2(T(e^{-1}))^2)(1 + 5T(e^{-1}) + 3(T(e^{-1}))^2 + (T(e^{-1}))^3)} {(1 - (1 - \sqrt 2 \cdot \sqrt {1 - ez}))^6(1 + T(e^{-1}))^3} \\
         & = \frac {(1 + 2 + 2)(1 + 5 + 3 + 1)} {2^3} \cdot \frac 1 {(\sqrt 2 )^6 (\sqrt{1 - ez})^6}                                                                              \\
         & = \frac {50} {64} \cdot \frac 1 {(1 - ez)^3}
    \end{align*}
    Folglich gilt mit der Notation von Satz 1 $\sigma(x) = x^3$ und $\alpha = 3$. Aus Satz 1 folgt
    \begin{align*}
        [x^n] \psi(x)
         & \sim \frac {50} {64} \cdot (e^{-1})^{-n} \cdot \frac {n^3} {n \Gamma(3)} \\
         & = \frac {25} {32} \cdot \frac {e^n n^2} {2}
    \end{align*}
    und mit Stirlings Näherung $n! \sim \sqrt{2\pi n} (n/e)^n$
    \begin{align*}
        \frac 1 {n^{n + 2}} \sum_{f \in A(n)} \;
         & \sum_{a \in \Z/n\Z} \; \sum_{b \in \Z/n\Z} \min(\nu(f, a), \nu(f, b))    \\
         & \sim \frac {n!}{n^{n + 2}} \cdot \frac {25} {32} \cdot \frac {e^n n^2} 2 \\
         & = n! \bigg (\frac {e} {n} \bigg )^n \cdot \frac {25} {64}                \\
         & \sim \sqrt {2 \pi n} \cdot \frac {25}{64}                                \\
         & = \frac {25} {32} \sqrt{\pi n/2}
    \end{align*}
\end{proof}

\noindent Mit obigen Annahmen über $L_K(p)$ folgt aus Satz 2 sofort $L_{1, 1}(p) \sim 25/32 \sqrt{\pi p / 2}$. Man bemerke außerdem, dass Satz 2 unabhängig von der Anwendung auf Pollards Rho-Algorithmus formuliert wurde und nicht auf heuristischen Annahmen basiert.

\section{Bestimmung optimaler Exponenten für die Rho-Methode}\label{sec:optk}

In diesem Abschnitt wird die Frage behandelt, wie der Paramter $k$ bei $M$ Maschinen bestmöglich gewählt werden kann. Mit Formel (\ref{lkp}) und Satz 2 konnten Ergebnisse in den Fällen $M = 1$ und $M = 2$ erzielt werden. Die grundlegende Strategie ist, den Erwartungswert von $L_K(p)$ über alle Möglichkeiten von $\gcd(p - 1, 2k_i)$ für alle $1 \le i \le M$ zu bilden und so einen Wert für die erwartete Laufzeit in Abhängigkeit der $k_i$ zu erhalten. Zur Berechnung der Wahrscheinlichkeit, dass $\gcd(p - 1, 2k_i)$ einen bestimmten Wert annimmt, wird folgendes Lemma benötigt.

\begin{lemma}
    Sei $1 \le n \in \N$ und $m$ eine zufällige natürliche Zahl, sodass $0 \le m \le n - 1$. Dann gilt für $d \in \N$
    \begin{align*}
        \mathbb{P}(\gcd(n, m) = d) = \frac {\varphi(n / d)} n
    \end{align*}
    wobei $\varphi$ die eulersche Phifunktion ist. Für $n/d \notin \N$ wird $\varphi(n/d) = 0$ definiert.
\end{lemma}

\begin{proof}
    Jede natürliche Zahl $m$ mit $\gcd(n, m) = d$ lässt sich als $m = da$ schreiben. Dabei muss $\gcd(a, n / d) = 1$ gelten, sonst wäre $\gcd(n, m) > d$. Auch gilt $0 \le a \le n/d - 1$. Umgekehrt gilt $\gcd(n, da) = d$ für jedes $0 \le a \le n/d - 1$ mit $\gcd(n/d, a) = 1$. Die Anzahl an $m \in \N$ mit $0 \le m \le n - 1$ mit $\gcd(n, m) = d$ ist also genau die Anzahl an $a \in \N$ mit $0 \le a \le  n / d - 1$ und $\gcd(n / d, a) = 1$. Diese Zahl ist aber genau $\varphi(n/d)$.
\end{proof}

\subsection{Der Fall einer Maschine}

\begin{theorem}
    Sei $L_k(p)$ wie in Abschnitt \ref{sec:par} definiert. Es gilt $\E(L_1(p)) < \E(L_k(p))$, wobei $1 < k \in \N$ und der Erwartungswert über alle möglichen $\gcd((p - 1)/2, k)$ genommen wird.
\end{theorem}

\begin{proof}
    Durch Einsetzen von $M = 1$ in (\ref{lkp}) erhalten wir
    \begin{align*}
        L_k(p) \sim \sqrt {\pi p / 2} \lg^2 2k \cdot \frac {1} {\sqrt{\gcd(p - 1, 2k) - 1}}
    \end{align*}
    Der Einfachheit halber wird hier $k$ für $k_1$ geschrieben. Die erwartete Laufzeit im Fall $k = 1$ ist folglich $\sqrt{\pi p/2}$, es wird also gezeigt, dass $\E(L_k(p)) > \sqrt{\pi p / 2}$ für $k > 1$. Der Erwartungswert von $L_k(p)$ wird über jede Möglichkeit von $\gcd(p - 1, 2k)$ gebildet. Da $p - 1$ gerade ist, gilt $\gcd(p - 1, 2k) = 2 \gcd((p - 1)/2, k)$. Unter der Annahme, dass jeder Rest von $(p - 1)/2 \bmod k$ gleich wahrscheinlich ist, was für eine Abschätzung der durchschnittlichen Laufzeit sinnvoll ist, gilt $\mathbb{P}(\gcd((p - 1)/2, k) = d) = \varphi(k/d)/k$. Daraus folgt
    \begin{align}
        \E(L_k(p))
         & = \sqrt{\pi p / 2} \lg^2 2k \cdot \sum_{d | k} \frac {\P(\gcd((p - 1)/2, k) = d)} { \sqrt {2d - 1}} \nonumber \\
         & \ge \sqrt{\pi p / 2} \lg^2 2k \cdot \frac {\varphi(k)} k \label{elk}
    \end{align}
    Sei $k = q_1^{e_1} q_2^{e_2} \cdots q_r^{e_r}$ für Primzahlen $q_i$. Folgende Methode, um $\varphi(k)/k$ nach unten zu beschränken, stammt von \cite{phi}.
    \begin{align*}
        \frac {\varphi(k)} k = \prod_{i = 1}^r \left ( \frac {q_i - 1} {q_i} \right )
        = \frac{\prod_{i = 1}^r \left ( 1 - \frac 1 {q_i^2} \right )}{\prod_{i = 1}^r \left ( 1 + \frac 1 {q_i} \right )}
        > \frac {\prod_{n = 2}^\infty \Big ( 1 - \frac 1 {n^2} \Big )} {\prod_{i = 1}^r \left ( 1 + \frac 1 {q_i} \right )}
        = \frac {\prod_{n = 2}^\infty \Big ( \frac {n - 1} {n} \Big ) \Big ( \frac {n + 1} n \Big )} {\prod_{i = 1}^r \left ( 1 + \frac 1 {q_i} \right )}
    \end{align*}
    Der Zähler ist ein Teleskopprodukt und folglich gleich dem ersten Faktor $1/2$. Der Nenner ist kleiner gleich $\sum_{n = 1}^{k} 1/n$ und kann folglich mit $1 + \ln k \le 1 + \lg k = \lg 2k$ nach oben begrenzt werden. Es gilt also
    \begin{align*}
        \frac {\varphi(k)} k
        > \frac {\prod_{n = 2}^\infty \Big ( \frac {n - 1} {n} \Big ) \Big ( \frac {n + 1} n \Big )} {\prod_{i = 1}^r \left ( 1 + \frac 1 {q_i} \right )}
        \ge \frac {1}{2\lg 2k}
    \end{align*}
    Durch Einsetzen in (\ref{elk}) ergibt sich insgesamt
    \begin{align*}
        \E(L_k) > \sqrt{\pi p / 2} \lg^2 2k \cdot \frac {1} {2 \lg 2k} = \sqrt {\pi p / 2} \cdot \frac {\lg 2k} {2}
    \end{align*}
    was für $k \ge 2$ die gewünschte Ungleichung liefert.
\end{proof}

\subsection{Der Fall zweier Maschinen}

Im Fall $M = 2$ konnte bewiesen werden, dass $k_1 = k_2 = 1$ besser ist als $k_1, k_2$ prim und $k_1 = k_2 > 1$. Es wird vermutet, dass $k_1 = k_2 = 1$ optimal ist, der Beweis scheint aber deutlich schwieriger als für $M = 1$. Während es im Fall $M = 1$ möglich war, nur mit dem Fall $\gcd((p - 1)/2, k) = 1$ eine ausreichend große untere Schranke zu erhalten, funktioniert das im Fall $M = 2$ nicht mehr.

\begin{theorem}
    Sei $L_{k_1, k_2}(p)$ wie in Abschnitt \ref{sec:par} definiert. Im Folgenden wird der Erwartungswert von $L_{k_1, k_2}$ über alle möglichen $\gcd((p - 1)/2, k_i)$ für $i = 1, 2$ genommen.
    \begin{enumerate}
        \item Wenn $q_1, q_2$ Primzahlen sind, gilt $\E(L_{1, 1}(p)) < \E(L_{q_1, q_2}(p))$.
        \item Wenn $1 < k \in \N$, gilt $\E(L_{1, 1}(p)) < \E(L_{k, k}(p))$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Es wird zunächst Teil 1 gezeigt. Gleichung (\ref{lkp}) mit $M = 2$ liefert
    \begin{align*}
        L_{k_1, k_2}(p) \sim \sqrt{\pi / 2} \ \Bigg (\frac 1 {h_1 \lg 2k_1} + \frac 1 {h_2 \lg 2k_2} \Bigg ) \Bigg ( \frac 1 {h_1 \lg^2 2k_1} + \frac 1 {h_2 \lg^2 2k_2} \Bigg )^{-3/2}
    \end{align*}
    Nach Abschnitt \ref{sec:start2} gilt $L_{1, 1}(p) \sim 25/32 \sqrt{\pi p /2}$, es gilt also $\E(L_{k_1, k_2}) > 25/32 \sqrt{\pi p /2}$ für $k_1 \ne 1$ oder $k_2 \ne 1$ zu zeigen. Wie im Fall $M = 1$ bilden wir den Erwartungswert über alle möglichen $\gcd((p - 1)/2, k_i)$.
    \begin{align*}
        \E(L_{k_1, k_2})
         & \sim \sqrt{\pi / 2} \sum_{d_1 | k_1} \P(\gcd((p - 1)/2, k_2) = d_1) \sum_{d_2 | k_2} \P(\gcd((p - 1)/2, k_2) = d_2)                                                                                           \\
         & \qquad \Bigg (\frac 1 {p / (2d_1-1)  \cdot \lg 2k_1} + \frac 1 {p / (2d_2-1) \cdot \lg 2k_2} \Bigg ) \Bigg ( \frac 1 {p / (2d_1-1) \cdot \lg^2 2k_1} + \frac 1 {p / (2d_2-1) \cdot \lg^2 2k_2} \Bigg )^{-3/2} \\
         & \ge \sqrt{\pi p / 2} \ \frac {\varphi(k_1)} {k_1} \ \frac {\varphi(k_2)} {k_2} \, \Bigg (\frac 1 {\lg 2k_1} + \frac 1 {\lg 2k_2} \Bigg ) \Bigg ( \frac 1 {\lg^2 2k_1} + \frac 1 {\lg^2 2k_2} \Bigg )^{-3/2}   \\
         & = \sqrt {\pi p / 2} \lg^2 2k_1 \cdot \lg^2 2k_2 \cdot \frac {\lg 2k_1 + \lg 2k_2} {(\lg^2 2k_1 + \lg^2 2k_2)^{3/2}}
    \end{align*}
    Nach der Dreiecksungleichung und $k_i \ge 1$ gilt $\lg 2k_1 + \lg 2k_2 > \sqrt{\lg^2 2k_1 + \lg^2 2k_2}$.
    \begin{align*}
        \sqrt {\pi p / 2} \ \lg^2 (2k_1) \lg^2 (2k_2) \ \frac {\lg 2k_1 + \lg 2k_2} {(\lg^2 2k_1 + \lg^2 2k_2)^{3/2}}
         & >  \sqrt {\pi p / 2} \ \frac {\lg^2 (2k_1) \lg^2 (2k_2)} {\lg^2 2k_1 + \lg^2 2k_2}
    \end{align*}
    Falls $k_1, k_2 \ge 2$, gilt $\lg^2 2k_i \ge 2 \ (i = 1, 2)$
\end{proof}

\section{Experimentelle Ergebnisse}\label{sec:ex}

\subsection{Die minimale Rho-Länge bei mehreren Anfangswerten}

\subsection{Experimentelle Bestimmung optimaler Parameter}

\section{Fazit}

\printbibliography

\end{document}